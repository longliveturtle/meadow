{"id":936,"date":"2016-02-11T18:29:03","date_gmt":"2016-02-11T18:29:03","guid":{"rendered":"http:\/\/dev2.hpc.ucla.edu\/r\/dae-3\/r-online-manual\/"},"modified":"2024-06-24T11:14:42","modified_gmt":"2024-06-24T18:14:42","slug":"zinb","status":"publish","type":"page","link":"https:\/\/stats.oarc.ucla.edu\/r\/dae\/zinb\/","title":{"rendered":"Zero-Inflated Negative Binomial Regression |  R Data Analysis Examples"},"content":{"rendered":"<p>Zero-inflated negative binomial regression is for modeling count variables\nwith excessive zeros and it is usually for\nover-dispersed count outcome variables. Furthermore, theory suggests that the\nexcess zeros are generated by a separate process from the count values and that\nthe excess zeros can be modeled independently.<\/p>\n<p>This page uses the following packages. Make sure that you can load\nthem before trying to run the examples on this page. If you do not have\na package installed, run: <code>install.packages(\"packagename\")<\/code>, or\nif you see the version is out of date, run: <code>update.packages()<\/code>.<\/p>\n<div id=\"unnamed-chunk-2\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">require<\/span><span class=\"hl std\">(ggplot2)<\/span>\r\n<span class=\"hl kwd\">require<\/span><span class=\"hl std\">(pscl)<\/span>\r\n<span class=\"hl kwd\">require<\/span><span class=\"hl std\">(MASS)<\/span>\r\n<span class=\"hl kwd\">require<\/span><span class=\"hl std\">(boot)<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p><code class=\"knitr inline\"><strong>Version info: <\/strong>Code for this page was tested in R version 3.1.1 (2014-07-10)\nOn: 2014-08-11\nWith: boot 1.3-11; knitr 1.6; pscl 1.04.4; vcd 1.3-1; gam 1.09.1; coda 0.16-1; mvtnorm 1.0-0; GGally 0.4.7; plyr 1.8.1; MASS 7.3-33; Hmisc 3.14-4; Formula 1.1-2; survival 2.37-7; psych 1.4.5; reshape2 1.4; msm 1.4; phia 0.1-5; RColorBrewer 1.0-5; effects 3.0-0; colorspace 1.2-4; lattice 0.20-29; pequod 0.0-3; car 2.0-20; ggplot2 1.0.0\n<\/code><\/p>\n<p><strong>Please note:<\/strong> The purpose of this page is to show how to use various data\nanalysis commands. It does not cover all aspects of the research process which\nresearchers are expected to do. In particular, it does not cover data\ncleaning and checking, verification of assumptions, model diagnostics or\npotential follow-up analyses.<\/p>\n<h2>Examples of zero-inflated negative binomial regression<\/h2>\n<p>Example 1. School administrators study the attendance behavior of high school\njuniors at two schools. Predictors of the number of days of absence include\ngender of the student and standardized test scores in math and language arts.<\/p>\n<p>Example 2. The state wildlife biologists want to model how many fish are\nbeing caught by fishermen at a state park. Visitors are asked how long they\nstayed, how many people were in the group, were there children in the group and\nhow many fish were caught. Some visitors do not fish, but there is no data on\nwhether a person fished or not. Some visitors who did fish did not catch any\nfish so there are excess zeros in the data because of the people that did not\nfish.<\/p>\n<h2>Description of the Data<\/h2>\n<p>Let&#8217;s pursue Example 2 from above.<\/p>\n<p>We have data on 250 groups that went to a park. Each group was questioned\nabout how many fish they caught (<code>count<\/code>), how many children were in the\ngroup (<code>child<\/code>), how many people were in the group (<code>persons<\/code>), and\nwhether or not they brought a camper to the park (<code>camper<\/code>).<\/p>\n<p>In addition to predicting the number of fish caught, there is interest in\npredicting the existence of excess zeros, i.e., the probability that a group\ncaught zero fish. We will use the variables <code>child<\/code>, <code>persons<\/code>, and\n<code>camper<\/code> in our model. Let&#8217;s look at the data.<\/p>\n<div id=\"unnamed-chunk-3\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">zinb<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">read.csv<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"https:\/\/stats.idre.ucla.edu\/stat\/data\/fish.csv\"<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl std\">zinb<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">within<\/span><span class=\"hl std\">(zinb, {<\/span>\r\n  <span class=\"hl std\">nofish<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(nofish)<\/span>\r\n  <span class=\"hl std\">livebait<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(livebait)<\/span>\r\n  <span class=\"hl std\">camper<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(camper)<\/span>\r\n<span class=\"hl std\">})<\/span>\r\n\r\n<span class=\"hl kwd\">summary<\/span><span class=\"hl std\">(zinb)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##  nofish  livebait camper     persons         child             xb        \r\n##  0:176   0: 34    0:103   Min.   :1.00   Min.   :0.000   Min.   :-3.275  \r\n##  1: 74   1:216    1:147   1st Qu.:2.00   1st Qu.:0.000   1st Qu.: 0.008  \r\n##                           Median :2.00   Median :0.000   Median : 0.955  \r\n##                           Mean   :2.53   Mean   :0.684   Mean   : 0.974  \r\n##                           3rd Qu.:4.00   3rd Qu.:1.000   3rd Qu.: 1.964  \r\n##                           Max.   :4.00   Max.   :3.000   Max.   : 5.353  \r\n##        zg             count      \r\n##  Min.   :-5.626   Min.   :  0.0  \r\n##  1st Qu.:-1.253   1st Qu.:  0.0  \r\n##  Median : 0.605   Median :  0.0  \r\n##  Mean   : 0.252   Mean   :  3.3  \r\n##  3rd Qu.: 1.993   3rd Qu.:  2.0  \r\n##  Max.   : 4.263   Max.   :149.0\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\">## histogram with x axis in log10 scale<\/span>\r\n<span class=\"hl kwd\">ggplot<\/span><span class=\"hl std\">(zinb,<\/span> <span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(count,<\/span> <span class=\"hl kwc\">fill<\/span> <span class=\"hl std\">= camper))<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">geom_histogram<\/span><span class=\"hl std\">()<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">scale_x_log10<\/span><span class=\"hl std\">()<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">facet_grid<\/span><span class=\"hl std\">(camper<\/span> <span class=\"hl opt\">~<\/span> <span class=\"hl std\">.,<\/span> <span class=\"hl kwc\">margins<\/span><span class=\"hl std\">=<\/span><span class=\"hl num\">TRUE<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">scales<\/span><span class=\"hl std\">=<\/span><span class=\"hl str\">\"free_y\"<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"message\">\n<pre class=\"knitr r\">## stat_bin: binwidth defaulted to range\/30. Use 'binwidth = x' to adjust this.\r\n## stat_bin: binwidth defaulted to range\/30. Use 'binwidth = x' to adjust this.\r\n## stat_bin: binwidth defaulted to range\/30. Use 'binwidth = x' to adjust this.\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/zinbreg-unnamed-chunk-3.png\" alt=\"plot of chunk unnamed-chunk-3\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<h2>Analysis methods you might consider<\/h2>\n<p>Before we show how you can analyze this with a zero-inflated negative binomial analysis, let&#8217;s\nconsider some other methods that you might use.<\/p>\n<ul>\n<li>OLS Regression &#8211; You could try to analyze these data using OLS regression. However, count\ndata are highly non-normal and are not well estimated by OLS regression.<\/li>\n<li>Zero-inflated Poisson Regression &#8211; Zero-inflated Poisson regression does better when\nthe data are not over-dispersed, i.e. when variance is not much larger than the mean.<\/li>\n<li>Ordinary Count Models &#8211; Poisson or negative binomial models might be more\nappropriate if there are not excess zeros.<\/li>\n<\/ul>\n<h2>Zero-inflated negative binomial regression<\/h2>\n<p>A zero-inflated model assumes that zero outcome is due to two different\nprocesses. For instance, in the example of fishing presented here, the two\nprocesses are that a subject has gone fishing vs. not gone fishing. If not gone fishing, the only\noutcome possible is zero. If gone fishing, it is then a count\nprocess. The two parts of the a zero-inflated model are a binary model, usually\na logit model to model which of the two processes the zero outcome is associated\nwith and a count model, in this case, a negative binomial model, to model the\ncount process. The expected count is expressed as a combination of the two\nprocesses. Taking the example of fishing again:<\/p>\n<p>$$\nE(n_{\\text{fish caught}} = k) = P(\\text{not gone fishing}) * 0 + P(\\text{gone fishing}) * E(y = k | \\text{gone fishing})\n$$<\/p>\n<p>To understand the zero-inflated negative binomial regression,\nlet&#8217;s start with the negative binomial model. There are multiple\nparameterizations of the negative binomial model, we focus on NB2.\nThe negative binomial probability density function is:<\/p>\n<p>$$\nPDF(y; p, r) = \\frac{(y_i + r &#8211; 1)!}{y_i!(r-1)!}p_{i}^{r}(1 &#8211; p_i)^{y_i}\n$$<\/p>\n<p>where (p) is the probability of (r) successes. From this we can derive\nthe likelihood function, which is given by:<\/p>\n<p>$$\nL(\\mu; y, \\alpha) = \\prod_{i=1}^{n}exp\\left(y_i ln\\left(\\frac{\\alpha\\mu_i}{1 +\\alpha\\mu_i}\\right)-\\frac{1}{\\alpha}ln(1 + \\alpha\\mu_i) + ln\\Gamma(y_i + \\frac{1}{\\alpha})-ln\\Gamma(y_i + 1) &#8211; ln\\Gamma(\\frac{1}{\\alpha})\\right)\n$$<\/p>\n<p>here we find the likelihood of the expected value, \\(\\mu\\) given the data and\n\\(\\alpha\\) which allows for dispersion. Typically, this would be expressed as\na log likelihood, denoted by script L, \\(\\mathcal{L}\\):<\/p>\n<p>$$\n\\mathcal{L}(\\mu; y, \\alpha) = \\sum_{i=1}^{n}y_i ln\\left(\\frac{\\alpha\\mu_i}{1 + \\alpha\\mu_i}\\right)-\\frac{1}{\\alpha}ln(1 + \\alpha\\mu_i) + ln\\Gamma(y_i + \\frac{1}{\\alpha})-ln\\Gamma(y_i + 1) &#8211; ln\\Gamma(\\frac{1}{\\alpha})\n$$<\/p>\n<p>which can be expressed in terms of our model by replacing \\(\\mu_i\\) with\n\\(exp(x_i&#8217;\\beta)\\). Turning to the zero-inflated negative binomial model,\nthe expression of the likelihood function depends on whether the observed value\nis a zero or greater than zero. From the logistic model of \\(y_i \\gt 1\\) versus\n\\(y = 0\\):<\/p>\n<p>$$\np = \\frac{1}{1 + e^{-x_i&#8217;\\beta}}\n$$<\/p>\n<p>and<\/p>\n<p>$$\n1 &#8211; p = \\frac{1}{1 + e^{x_i&#8217;\\beta}}\n$$<\/p>\n<p>then<\/p>\n<p>$$\n\\mathcal{L} = \\left\\{ \\begin{array}{ll} \\sum_{i=1}^{n} \\left[ ln(p_{i}) + (1 &#8211; p_i)\\left(\\frac{1}{1 + \\alpha\\mu_{i}}\\right)^{\\frac{1}{\\alpha}} \\right] &amp;\\mbox{if } y_{i} = 0 \\\\\n\\sum_{i=1}^{n} \\left[ ln(p_{i}) + ln\\Gamma\\left(\\frac{1}{\\alpha} + y_i\\right) &#8211; ln\\Gamma(y_i + 1) &#8211; ln\\Gamma\\left(\\frac{1}{\\alpha}\\right) + \\left(\\frac{1}{\\alpha}\\right)ln\\left(\\frac{1}{1 + \\alpha\\mu_{i}}\\right) + y_iln\\left(1 &#8211; \\frac{1}{1 + \\alpha\\mu_{i}}\\right) \\right] &amp;\\mbox{if } y_{i} &gt; 0 \\end{array} \\right.\n$$<\/p>\n<p>Finally, note that R does not estimate \\(\\alpha\\) but \\(\\theta\\), the\ninverse of \\(\\alpha\\).<\/p>\n<p>Now let&#8217;s build up our model. We are going to use the variables\n<code>child<\/code> and <code>camper<\/code> to model the count in the part of negative\nbinomial model and the variable <code>persons<\/code> in the logit part of the model.\nWe use the <code>pscl<\/code> to run a zero-inflated negative binomial\nregression. We begin by estimating the model with the variables of interest.<\/p>\n<div id=\"unnamed-chunk-4\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">m1<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">zeroinfl<\/span><span class=\"hl std\">(count<\/span> <span class=\"hl opt\">~<\/span> <span class=\"hl std\">child<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">camper<\/span> <span class=\"hl opt\">|<\/span> <span class=\"hl std\">persons,<\/span>\r\n  <span class=\"hl kwc\">data<\/span> <span class=\"hl std\">= zinb,<\/span> <span class=\"hl kwc\">dist<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"negbin\"<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl kwd\">summary<\/span><span class=\"hl std\">(m1)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## \r\n## Call:\r\n## zeroinfl(formula = count ~ child + camper | persons, data = zinb, \r\n##     dist = \"negbin\", EM = TRUE)\r\n## \r\n## Pearson residuals:\r\n##    Min     1Q Median     3Q    Max \r\n## -0.586 -0.462 -0.389 -0.197 18.013 \r\n## \r\n## Count model coefficients (negbin with log link):\r\n##             Estimate Std. Error z value Pr(&gt;|z|)    \r\n## (Intercept)    1.371      0.256    5.35  8.6e-08 ***\r\n## child         -1.515      0.196   -7.75  9.4e-15 ***\r\n## camper1        0.879      0.269    3.26   0.0011 ** \r\n## Log(theta)    -0.985      0.176   -5.60  2.1e-08 ***\r\n## \r\n## Zero-inflation model coefficients (binomial with logit link):\r\n##             Estimate Std. Error z value Pr(&gt;|z|)  \r\n## (Intercept)    1.603      0.836    1.92    0.055 .\r\n## persons       -1.666      0.679   -2.45    0.014 *\r\n## ---\r\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \r\n## \r\n## Theta = 0.373 \r\n## Number of iterations in BFGS optimization: 2 \r\n## Log-likelihood: -433 on 6 Df\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>The output looks very much like the output from two OLS regressions in R.<\/p>\n<p>Below the model call, you will find a block of output containing negative\nbinomial regression coefficients for each of the variables along with\nstandard errors, z-scores, and p-values for the coefficients. A second block\nfollows that corresponds to the inflation model. This includes logit\ncoefficients for predicting excess zeros along with their standard errors,\nz-scores, and p-values.<\/p>\n<p>All of the predictors in both the count and inflation portions of the\nmodel are statistically significant. This model fits the data significantly\nbetter than the null model, i.e., the intercept-only model. To show that\nthis is the case, we can compare with the current model to a null model\nwithout predictors using chi-squared test on the difference of log\nlikelihoods.<\/p>\n<div id=\"unnamed-chunk-5\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">m0<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">update<\/span><span class=\"hl std\">(m1, .<\/span> <span class=\"hl opt\">~<\/span> <span class=\"hl num\">1<\/span><span class=\"hl std\">)<\/span>\r\n\r\n<span class=\"hl kwd\">pchisq<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">2<\/span> <span class=\"hl opt\">*<\/span> <span class=\"hl std\">(<\/span><span class=\"hl kwd\">logLik<\/span><span class=\"hl std\">(m1)<\/span> <span class=\"hl opt\">-<\/span> <span class=\"hl kwd\">logLik<\/span><span class=\"hl std\">(m0)),<\/span> <span class=\"hl kwc\">df<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">3<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">lower.tail<\/span><span class=\"hl std\">=<\/span><span class=\"hl num\">FALSE<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## 'log Lik.' 1.28e-13 (df=6)\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>From the output above, we can see that our overall model is statistically significant.<\/p>\n<ul>\n<li>The predictors <code>child<\/code> and <code>camper<\/code> in the part of the\nnegative binomial regression model predicting number\nof fish caught (<code>count<\/code>) are both significant predictors.<\/li>\n<li>The predictor <code>person<\/code> in the part of the logit model predicting\nexcessive zeros is statistically significant.<\/li>\n<li>For these data, the expected change in log(<code>count<\/code>)\nfor a one-unit increase in <code>child<\/code> is -1.515255 holding other variables constant.<\/li>\n<li>A camper (<code>camper<\/code> = 1) has an expected log(<code>count<\/code>)\nof 0.879051 higher than that of a non-camper (<code>camper<\/code> = 0) holding\nother variables constant.<\/li>\n<li>The log odds of being an excessive zero would decrease by 1.67 for every\nadditional person in the group. In other words, the more people in the group\nthe less likely that the zero would be due to not gone fishing. Put\nplainly, the larger the group the person was in, the more likely that the\nperson went fishing.<\/li>\n<\/ul>\n<p>We can get confidence intervals for the parameters and the\nexponentiated parameters using bootstrapping. For the negative binomial model, these would\nbe incident risk ratios, for the zero inflation model, odds ratios. We use the\n<code>boot<\/code> package. First, we get the coefficients from our original model to\nuse as start values for the model to speed up the time it takes to estimate. Then\nwe write a short function that takes data and indices as input and returns the\nparameters we are interested in. Finally, we pass that\nto the <code>boot<\/code> function and do 1200 replicates, using snow to distribute across\nfour cores. Note that you should adjust the number of cores to whatever your machine\nhas. Also, for final results, one may wish to increase the number of replications to\nhelp ensure stable results.<\/p>\n<div id=\"unnamed-chunk-7\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">dput<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">round<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">coef<\/span><span class=\"hl std\">(m1,<\/span> <span class=\"hl str\">\"count\"<\/span><span class=\"hl std\">),<\/span> <span class=\"hl num\">4<\/span><span class=\"hl std\">))<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## structure(c(1.3711, -1.5152, 0.879), .Names = c(\"(Intercept)\", \r\n## \"child\", \"camper1\"))\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">dput<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">round<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">coef<\/span><span class=\"hl std\">(m1,<\/span> <span class=\"hl str\">\"zero\"<\/span><span class=\"hl std\">),<\/span> <span class=\"hl num\">4<\/span><span class=\"hl std\">))<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## structure(c(1.6028, -1.6663), .Names = c(\"(Intercept)\", \"persons\"\r\n## ))\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">f<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">data<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">i<\/span><span class=\"hl std\">) {<\/span>\r\n  <span class=\"hl kwd\">require<\/span><span class=\"hl std\">(pscl)<\/span>\r\n  <span class=\"hl std\">m<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">zeroinfl<\/span><span class=\"hl std\">(count<\/span> <span class=\"hl opt\">~<\/span> <span class=\"hl std\">child<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">camper<\/span> <span class=\"hl opt\">|<\/span> <span class=\"hl std\">persons,<\/span>\r\n    <span class=\"hl kwc\">data<\/span> <span class=\"hl std\">= data[i, ],<\/span> <span class=\"hl kwc\">dist<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"negbin\"<\/span><span class=\"hl std\">,<\/span>\r\n    <span class=\"hl kwc\">start<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">list<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">count<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">1.3711<\/span><span class=\"hl std\">,<\/span> <span class=\"hl opt\">-<\/span><span class=\"hl num\">1.5152<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">0.879<\/span><span class=\"hl std\">),<\/span> <span class=\"hl kwc\">zero<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">1.6028<\/span><span class=\"hl std\">,<\/span> <span class=\"hl opt\">-<\/span><span class=\"hl num\">1.6663<\/span><span class=\"hl std\">)))<\/span>\r\n  <span class=\"hl kwd\">as.vector<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">t<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">do.call<\/span><span class=\"hl std\">(rbind,<\/span> <span class=\"hl kwd\">coef<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">summary<\/span><span class=\"hl std\">(m)))[,<\/span> <span class=\"hl num\">1<\/span><span class=\"hl opt\">:<\/span><span class=\"hl num\">2<\/span><span class=\"hl std\">]))<\/span>\r\n<span class=\"hl std\">}<\/span>\r\n\r\n<span class=\"hl kwd\">set.seed<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">10<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl std\">(res<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">boot<\/span><span class=\"hl std\">(zinb, f,<\/span> <span class=\"hl kwc\">R<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">1200<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">parallel<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"snow\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">ncpus<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">4<\/span><span class=\"hl std\">))<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## \r\n## ORDINARY NONPARAMETRIC BOOTSTRAP\r\n## \r\n## \r\n## Call:\r\n## boot(data = zinb, statistic = f, R = 1200, parallel = \"snow\", \r\n##     ncpus = 4)\r\n## \r\n## \r\n## Bootstrap Statistics :\r\n##      original    bias    std. error\r\n## t1*    1.3711 -0.083023     0.39403\r\n## t2*    0.2561 -0.002622     0.03191\r\n## t3*   -1.5153 -0.061487     0.26892\r\n## t4*    0.1956  0.006034     0.02027\r\n## t5*    0.8791  0.091431     0.47124\r\n## t6*    0.2693  0.001873     0.01998\r\n## t7*   -0.9854  0.080120     0.21896\r\n## t8*    0.1760  0.002577     0.01689\r\n## t9*    1.6031  0.473597     1.59331\r\n## t10*   0.8365  3.767327    15.65780\r\n## t11*  -1.6666 -0.462364     1.56789\r\n## t12*   0.6793  3.771994    15.69675\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>The results are alternating parameter estimates and standard\nerrors. That is, the first row has the first parameter estimate\nfrom our model. The second has the standard error for the\nfirst parameter. The third column contains the bootstrapped\nstandard errors, which are considerably larger than those estimated\nby <code>zeroinfl<\/code>.<\/p>\n<p>Now we can get the confidence intervals for all the parameters.\nWe start on the original scale with percentile and bias adjusted CIs.\nWe also compare these results with the regular confidence intervals\nbased on the standard errors.<\/p>\n<div id=\"unnamed-chunk-8\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\">## basic parameter estimates with percentile and bias adjusted CIs<\/span>\r\n<span class=\"hl std\">parms<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">t<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">sapply<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">1<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">3<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">5<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">9<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">11<\/span><span class=\"hl std\">),<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">i<\/span><span class=\"hl std\">) {<\/span>\r\n  <span class=\"hl std\">out<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">boot.ci<\/span><span class=\"hl std\">(res,<\/span> <span class=\"hl kwc\">index<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(i, i<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl num\">1<\/span><span class=\"hl std\">),<\/span> <span class=\"hl kwc\">type<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"perc\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"bca\"<\/span><span class=\"hl std\">))<\/span>\r\n  <span class=\"hl kwd\">with<\/span><span class=\"hl std\">(out,<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">Est<\/span> <span class=\"hl std\">= t0,<\/span> <span class=\"hl kwc\">pLL<\/span> <span class=\"hl std\">= percent[<\/span><span class=\"hl num\">4<\/span><span class=\"hl std\">],<\/span> <span class=\"hl kwc\">pUL<\/span> <span class=\"hl std\">= percent[<\/span><span class=\"hl num\">5<\/span><span class=\"hl std\">],<\/span>\r\n    <span class=\"hl kwc\">bcaLL<\/span> <span class=\"hl std\">= bca[<\/span><span class=\"hl num\">4<\/span><span class=\"hl std\">],<\/span> <span class=\"hl kwc\">bcaUL<\/span> <span class=\"hl std\">= bca[<\/span><span class=\"hl num\">5<\/span><span class=\"hl std\">]))<\/span>\r\n<span class=\"hl std\">}))<\/span>\r\n\r\n<span class=\"hl com\">## add row names<\/span>\r\n<span class=\"hl kwd\">row.names<\/span><span class=\"hl std\">(parms)<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">names<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">coef<\/span><span class=\"hl std\">(m1))<\/span>\r\n<span class=\"hl com\">## print results<\/span>\r\n<span class=\"hl std\">parms<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##                      Est     pLL     pUL   bcaLL   bcaUL\r\n## count_(Intercept)  1.3711  0.5676  2.0620  0.7226  2.2923\r\n## count_child       -1.5153 -2.1382 -1.0887 -2.0175 -0.9593\r\n## count_camper1      0.8791  0.0431  1.8331 -0.2016  1.6669\r\n## zero_(Intercept)   1.6031  0.4344  8.2380  0.0282  3.5197\r\n## zero_persons      -1.6666 -8.5436 -1.1002 -7.8329 -1.0781\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\">## compare with normal based approximation<\/span>\r\n<span class=\"hl kwd\">confint<\/span><span class=\"hl std\">(m1)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##                      2.5 %  97.5 %\r\n## count_(Intercept)  0.86911  1.8731\r\n## count_child       -1.89860 -1.1319\r\n## count_camper1      0.35127  1.4068\r\n## zero_(Intercept)  -0.03636  3.2419\r\n## zero_persons      -2.99701 -0.3355\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>The bootstrapped confidence intervals are considerably wider than the\nnormal based approximation. The bootstrapped CIs are more consistent with\nthe CIs from Stata when using robust standard errors.<\/p>\n<p>Now we can estimate the incident risk ratio (IRR) for the negative binomial model and\nodds ratio (OR) for the logistic (zero inflation) model. This is done using\nalmost identical code as before, but passing a transformation function to the\n<code>h<\/code> argument of <code>boot.ci<\/code>, in this case, <code>exp<\/code> to exponentiate.<\/p>\n<div id=\"unnamed-chunk-9\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\">## exponentiated parameter estimates with percentile and bias adjusted CIs<\/span>\r\n<span class=\"hl std\">expparms<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">t<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">sapply<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">1<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">3<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">5<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">9<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">11<\/span><span class=\"hl std\">),<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">i<\/span><span class=\"hl std\">) {<\/span>\r\n  <span class=\"hl std\">out<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">boot.ci<\/span><span class=\"hl std\">(res,<\/span> <span class=\"hl kwc\">index<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(i, i<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl num\">1<\/span><span class=\"hl std\">),<\/span> <span class=\"hl kwc\">type<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"perc\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"bca\"<\/span><span class=\"hl std\">),<\/span> <span class=\"hl kwc\">h<\/span> <span class=\"hl std\">= exp)<\/span>\r\n  <span class=\"hl kwd\">with<\/span><span class=\"hl std\">(out,<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">Est<\/span> <span class=\"hl std\">= t0,<\/span> <span class=\"hl kwc\">pLL<\/span> <span class=\"hl std\">= percent[<\/span><span class=\"hl num\">4<\/span><span class=\"hl std\">],<\/span> <span class=\"hl kwc\">pUL<\/span> <span class=\"hl std\">= percent[<\/span><span class=\"hl num\">5<\/span><span class=\"hl std\">],<\/span>\r\n    <span class=\"hl kwc\">bcaLL<\/span> <span class=\"hl std\">= bca[<\/span><span class=\"hl num\">4<\/span><span class=\"hl std\">],<\/span> <span class=\"hl kwc\">bcaUL<\/span> <span class=\"hl std\">= bca[<\/span><span class=\"hl num\">5<\/span><span class=\"hl std\">]))<\/span>\r\n<span class=\"hl std\">}))<\/span>\r\n\r\n<span class=\"hl com\">## add row names<\/span>\r\n<span class=\"hl kwd\">row.names<\/span><span class=\"hl std\">(expparms)<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">names<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">coef<\/span><span class=\"hl std\">(m1))<\/span>\r\n<span class=\"hl com\">## print results<\/span>\r\n<span class=\"hl std\">expparms<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##                      Est    pLL       pUL  bcaLL   bcaUL\r\n## count_(Intercept) 3.9395 1.7641    7.8615 2.0599  9.8981\r\n## count_child       0.2198 0.1179    0.3367 0.1330  0.3832\r\n## count_camper1     2.4086 1.0441    6.2534 0.8175  5.2958\r\n## zero_(Intercept)  4.9686 1.5441 3781.9642 1.0286 33.7757\r\n## zero_persons      0.1889 0.0002    0.3328 0.0004  0.3402\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>To better understand our model, we can compute the expected number of fish\ncaught for different combinations of our predictors. In fact, since we are\nworking with essentially categorical predictors, we can compute the expected\nvalues for all combinations using the <code>expand.grid<\/code> function to create\nall combinations and then the <code>predict<\/code> function to do it. Finally we\ncreate a graph.<\/p>\n<div id=\"unnamed-chunk-10\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">newdata1<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">expand.grid<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">0<\/span><span class=\"hl opt\">:<\/span><span class=\"hl num\">3<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">0<\/span><span class=\"hl opt\">:<\/span><span class=\"hl num\">1<\/span><span class=\"hl std\">),<\/span> <span class=\"hl num\">1<\/span><span class=\"hl opt\">:<\/span><span class=\"hl num\">4<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl kwd\">colnames<\/span><span class=\"hl std\">(newdata1)<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"child\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"camper\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"persons\"<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl std\">newdata1<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">phat<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">predict<\/span><span class=\"hl std\">(m1, newdata1)<\/span>\r\n\r\n<span class=\"hl kwd\">ggplot<\/span><span class=\"hl std\">(newdata1,<\/span> <span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">x<\/span> <span class=\"hl std\">= child,<\/span> <span class=\"hl kwc\">y<\/span> <span class=\"hl std\">= phat,<\/span> <span class=\"hl kwc\">colour<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(persons)))<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">geom_point<\/span><span class=\"hl std\">()<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">geom_line<\/span><span class=\"hl std\">()<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">facet_wrap<\/span><span class=\"hl std\">(<\/span><span class=\"hl opt\">~<\/span><span class=\"hl std\">camper)<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">labs<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">x<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"Number of Children\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">y<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"Predicted Fish Caught\"<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/zinbreg-unnamed-chunk-10.png\" alt=\"plot of chunk unnamed-chunk-10\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<h2>Things to consider<\/h2>\n<p>Here are some issues that you may want to consider in the course of your\nresearch analysis.<\/p>\n<ul>\n<li>Question about the over-dispersion parameter is in general a tricky one.\nA large over-dispersion parameter could be due to a miss-specified model or\ncould be due to a real process with over-dispersion. Adding an\nover-dispersion problem does not necessarily improve a miss-specified model.<\/li>\n<li>The zero inflated negative binomial model has two parts, a negative binomial count model and\nthe logit model for predicting excess zeros, so you might want to review\nthese Data Analysis Example pages,\n<a href=\"\/r\/dae\/negative-binomial-regression\/\">Negative Binomial\nRegression<\/a> and\n<a href=\"\/r\/dae\/logit-regression\/\">Logit Regression<\/a>.<\/li>\n<li>Since zero inflated negative binomial has both a count model and a logit model, each of the\ntwo models should have good predictors. The two models do not necessarily\nneed to use the same predictors.<\/li>\n<li>Problems of perfect prediction, separation or partial separation can\noccur in the logistic part of the zero-inflated model.<\/li>\n<li>Count data often use exposure variable to indicate the number of times\nthe event could have happened. You can incorporate exposure (also called an offset)\ninto your model by using the <code>offset()<\/code> function.<\/li>\n<li>It is not recommended that zero-inflated negative binomial models be\napplied to small samples. What constitutes a small sample does not seem to\nbe clearly defined in the literature.<\/li>\n<li>Pseudo-R-squared values differ from OLS R-squareds, please see\n<a href=\"https:\/\/stats.idre.ucla.edu\/other\/mult-pkg\/faq\/general\/faq-what-are-pseudo-r-squareds\/\">FAQ: What are pseudo R-squareds?<\/a>\nfor a discussion on this issue.<\/li>\n<li>In times past, the Vuong test had been used to test whether a zero-inflated negative binomial model or a negative binomial model (without the zero-inflation) was a better fit for the data.\u00a0 However, this test is no longer considered valid.\u00a0 Please see <a href=\"http:\/\/cybermetrics.wlv.ac.uk\/paperdata\/misusevuong.pdf\">The Misuse of The Vuong Test For Non-Nested Models to Test for Zero-Inflation<\/a> by Paul Wilson for further information.<\/li>\n<\/ul>\n<h3>References<\/h3>\n<ul>\n<li>Long, J. S. 1997.\n<i>Regression Models for Categorical and Limited Dependent Variables.<\/i>\nThousand Oaks, CA: Sage Publications. Everitt, B. S. and Hothorn, T.\n<a href=\"http:\/\/cran.r-project.org\/web\/packages\/HSAUR\/vignettes\/preface.pdf\">\nA Handbook of Statistical Analyses Using R<\/a><\/li>\n<\/ul>\n<p><!--?php include \"stat\/footer.htm\"; ?--><\/p>\n","protected":false},"excerpt":{"rendered":"<p>Zero-inflated negative binomial regression is for modeling count variables with excessive zeros and it is usually for over-dispersed count outcome variables. Furthermore, theory suggests that the excess zeros are generated&#8230;<br><a class=\"moretag\" href=\"https:\/\/stats.oarc.ucla.edu\/r\/dae\/zinb\/\"> Read More<\/a><\/p>\n","protected":false},"author":1,"featured_media":0,"parent":916,"menu_order":18,"comment_status":"closed","ping_status":"closed","template":"","meta":{"_genesis_hide_title":false,"_genesis_hide_breadcrumbs":false,"_genesis_hide_singular_image":false,"_genesis_hide_footer_widgets":false,"_genesis_custom_body_class":"","_genesis_custom_post_class":"","_genesis_layout":"","footnotes":""},"class_list":["post-936","page","type-page","status-publish","entry"],"_links":{"self":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/936","targetHints":{"allow":["GET"]}}],"collection":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/comments?post=936"}],"version-history":[{"count":26,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/936\/revisions"}],"predecessor-version":[{"id":37450,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/936\/revisions\/37450"}],"up":[{"embeddable":true,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/916"}],"wp:attachment":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/media?parent=936"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}