{"id":924,"date":"2016-02-11T18:29:03","date_gmt":"2016-02-11T18:29:03","guid":{"rendered":"http:\/\/dev2.hpc.ucla.edu\/r\/dae-3\/r-data-analysis-examples-mixed-effects-logistic-regression\/"},"modified":"2021-08-25T13:42:43","modified_gmt":"2021-08-25T20:42:43","slug":"mixed-effects-logistic-regression","status":"publish","type":"page","link":"https:\/\/stats.oarc.ucla.edu\/r\/dae\/mixed-effects-logistic-regression\/","title":{"rendered":"Mixed Effects Logistic Regression |  R Data Analysis Examples"},"content":{"rendered":"<p><!--[mathjax]--><\/p>\n<p>Mixed effects logistic regression is used to model binary outcome variables,\nin which the log odds of the outcomes are modeled as a linear\ncombination of the predictor variables when data are clustered or there are\nboth fixed and random effects.<\/p>\n<p>This page uses the following packages. Make sure that you can load\nthem before trying to run the examples on this page. If you do not have\na package installed, run: <code>install.packages(\"packagename\")<\/code>, or\nif you see the version is out of date, run: <code>update.packages()<\/code>.<\/p>\n<div id=\"unnamed-chunk-2\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">require<\/span><span class=\"hl std\">(ggplot2)<\/span>\r\n<span class=\"hl kwd\">require<\/span><span class=\"hl std\">(GGally)<\/span>\r\n<span class=\"hl kwd\">require<\/span><span class=\"hl std\">(reshape2)<\/span>\r\n<span class=\"hl kwd\">require<\/span><span class=\"hl std\">(lme4)<\/span>\r\n<span class=\"hl kwd\">require<\/span><span class=\"hl std\">(compiler)<\/span>\r\n<span class=\"hl kwd\">require<\/span><span class=\"hl std\">(parallel)<\/span>\r\n<span class=\"hl kwd\">require<\/span><span class=\"hl std\">(boot)<\/span>\r\n<span class=\"hl kwd\">require<\/span><span class=\"hl std\">(lattice)<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p><code class=\"knitr inline\"><strong>Version info: <\/strong>Code for this page was tested in R version 3.1.0 (2014-04-10)\nOn: 2014-07-10\nWith: boot 1.3-11; lme4 1.1-6; Rcpp 0.11.2; Matrix 1.1-3; GGally 0.4.4; reshape 0.8.4; plyr 1.8; xtable 1.7-3; car 2.0-20; foreign 0.8-61; Hmisc 3.14-4; Formula 1.1-1; survival 2.37-7; lattice 0.20-29; mgcv 1.7-29; nlme 3.1-117; png 0.1-7; gridExtra 0.9.1; reshape2 1.2.2; ggplot2 0.9.3.1; vcd 1.3-1; rjson 0.2.14; RSQLite 0.11.4; DBI 0.2-7; knitr 1.5\n<\/code><\/p>\n<p><strong>Please note:<\/strong> The purpose of this page is to show how to use various\ndata analysis commands. It does not cover all aspects of the research process\nwhich researchers are expected to do. In particular, it does not cover data\ncleaning and checking, verification of assumptions, model diagnostics or\npotential follow-up analyses.<\/p>\n<h2>Examples of mixed effects logistic regression<\/h2>\n<p><strong>Example 1:<\/strong> A researcher sampled applications to 40 different colleges to study\nfactor that predict admittance into college. Predictors include student&#8217;s high school GPA,\nextracurricular activities, and SAT scores. Some schools are more or less selective, so the baseline\nprobability of admittance into each of the schools is different. School level predictors include\nwhether the school is public or private, the current student-to-teacher ratio, and the school&#8217;s rank.<\/p>\n<p><strong>Example 2:<\/strong> A large HMO wants to know what patient and physician factors are\nmost related to whether a patient&#8217;s lung cancer goes into remission after treatment as part of\na larger study of treatment outcomes and quality of life in patients with lunger cancer.<\/p>\n<p><strong>Example 3:<\/strong> A television station wants to know how time and advertising campaigns\naffect whether people view a television show. They sample people from four cities\nfor six months. Each month, they ask whether the people had watched a particular\nshow or not in the past week. After three months, they introduced a new advertising\ncampaign in two of the four cities and continued monitoring whether or not people had\nwatched the show.<\/p>\n<h2>Description of the data<\/h2>\n<p>In this example, we are going to explore Example 2 about lung cancer using a simulated\ndataset, which we have posted online. A variety of outcomes were collected on\npatients, who are nested within doctors, who are in turn nested within hospitals.\nThere are also a few doctor level variables, such as <code>Experience<\/code>\nthat we will use in our example.<\/p>\n<div id=\"unnamed-chunk-3\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">hdp<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">read.csv<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"https:\/\/stats.idre.ucla.edu\/stat\/data\/hdp.csv\"<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl std\">hdp<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">within<\/span><span class=\"hl std\">(hdp, {<\/span>\r\n  <span class=\"hl std\">Married<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(Married,<\/span> <span class=\"hl kwc\">levels<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">0<\/span><span class=\"hl opt\">:<\/span><span class=\"hl num\">1<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">labels<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"no\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"yes\"<\/span><span class=\"hl std\">))<\/span>\r\n  <span class=\"hl std\">DID<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(DID)<\/span>\r\n  <span class=\"hl std\">HID<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(HID)\r\n<\/span>  CancerStage &lt;- factor(CancerStage)\r\n<span class=\"hl std\">})<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>Now we are going to graph our continuous predictor variables.\nVisualizing data can help us understand the distributions,\ncatch coding errors (e.g., we know a variable only takes values\nfrom 0 to 7, but we see a 999 in the graph), and give us a\nsense of the relationship among our variables. For example,\nwe might see that two predictors are highly correlated and\ndecide we only want to include one in the model, or we might\nnote a curvilinear relation between two variables. Data\nvisualization is a fast, intuitive way to check all of this at\nonce. If most your predictors appear independent of each\nother, that is fine. It shapes your expectations of the model.\nFor example, if they are independent, the estimate for one predictor\nshould not change much when you enter another predictor (although\nthe standard error and significance tests may). We can get all of this\ninformation and intuition about what and how to model are data\nby simply viewing it.<\/p>\n<div id=\"unnamed-chunk-4\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">ggpairs<\/span><span class=\"hl std\">(hdp[,<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"IL6\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"CRP\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"LengthofStay\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"Experience\"<\/span><span class=\"hl std\">)])<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/melogit-unnamed-chunk-4.png\" alt=\"Scatter plot matrix of continuous variables\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<p>There do not seem to be any strong linear relations among our continuous\npredictors. Let us look at the distributions of our variables by\n<code>CancerStage<\/code>.\nBecause <code>LengthofStay<\/code> is coded discretely in days,\nwe can examine how <code>CancerStage<\/code> is associated\nwith it using bubble plots. The area of each bubble is\nproportional to the number of observations with those values.\nFor the continuous predictors, we use violin plots with jittered\ndata values. All of the raw data is presented separated by\n<code>CancerStage<\/code>. To alleviate overplotting and see the\nvalues better, we add a small amount of random noise (primarily\nto the x axis) as well as set the alpha transparency.\nAlthough the jittered dots are helpful for seeing the raw data,\nit can be difficult to get a precise sense of the distribution.\nFor that, we add violin plots. Violin plots are just kernel\ndensity plots reflected around the plotting axis. We plot the\nviolin plots on top of the jittered points with a transparency\nso that you can stil see the raw data, but the violin plots are\ndominant. Because both <code>IL6<\/code> and <code>CRP<\/code>\ntend to have skewed distributions, we use a square root scale\non the y axis. The distributions look fairly normal and symmetric,\nalthough you can still see the long right tail, even using a\nsquare root scale (note that only the scale was shifted, the\nvalues themselves are not transformed, which is important\nbecause this lets you see and interpret the actual scores,\nrather than the square root of the scores).<\/p>\n<div id=\"unnamed-chunk-5\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">ggplot<\/span><span class=\"hl std\">(hdp,<\/span> <span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">x<\/span> <span class=\"hl std\">= CancerStage,<\/span> <span class=\"hl kwc\">y<\/span> <span class=\"hl std\">= LengthofStay))<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">stat_sum<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">size<\/span> <span class=\"hl std\">= ..n..,<\/span> <span class=\"hl kwc\">group<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">1<\/span><span class=\"hl std\">))<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">scale_size_area<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">max_size<\/span><span class=\"hl std\">=<\/span><span class=\"hl num\">10<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/melogit-unnamed-chunk-51.png\" alt=\"Bubble plot of number of people with each length of stay by cancer stage\" width=\"500px\" height=\"500px\" \/><\/div>\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">tmp<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">melt<\/span><span class=\"hl std\">(hdp[,<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"CancerStage\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"IL6\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"CRP\"<\/span><span class=\"hl std\">)],<\/span> <span class=\"hl kwc\">id.vars<\/span><span class=\"hl std\">=<\/span><span class=\"hl str\">\"CancerStage\"<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl kwd\">ggplot<\/span><span class=\"hl std\">(tmp,<\/span> <span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">x<\/span> <span class=\"hl std\">= CancerStage,<\/span> <span class=\"hl kwc\">y<\/span> <span class=\"hl std\">= value))<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">geom_jitter<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">alpha<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">.1<\/span><span class=\"hl std\">)<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">geom_violin<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">alpha<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">.75<\/span><span class=\"hl std\">)<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">facet_grid<\/span><span class=\"hl std\">(variable<\/span> <span class=\"hl opt\">~<\/span> <span class=\"hl std\">.)<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">scale_y_sqrt<\/span><span class=\"hl std\">()<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/melogit-unnamed-chunk-52.png\" alt=\"Violin plots over jittered data points of values for IL6 and CRP by CancerStage on a square root scale\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<p>Because it is difficult to see how binary variables change\nover levels of continuous variables, we can flip the problem around\nand look at the distribution of continuous variables at each level\nof the binary outcome.<\/p>\n<div id=\"unnamed-chunk-6\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">tmp<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">melt<\/span><span class=\"hl std\">(hdp[,<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"remission\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"IL6\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"CRP\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"LengthofStay\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"Experience\"<\/span><span class=\"hl std\">)],<\/span>\r\n  <span class=\"hl kwc\">id.vars<\/span><span class=\"hl std\">=<\/span><span class=\"hl str\">\"remission\"<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl kwd\">ggplot<\/span><span class=\"hl std\">(tmp,<\/span> <span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(remission),<\/span> <span class=\"hl kwc\">y<\/span> <span class=\"hl std\">= value,<\/span> <span class=\"hl kwc\">fill<\/span><span class=\"hl std\">=<\/span><span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(remission)))<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">geom_boxplot<\/span><span class=\"hl std\">()<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">facet_wrap<\/span><span class=\"hl std\">(<\/span><span class=\"hl opt\">~<\/span><span class=\"hl std\">variable,<\/span> <span class=\"hl kwc\">scales<\/span><span class=\"hl std\">=<\/span><span class=\"hl str\">\"free_y\"<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/melogit-unnamed-chunk-6.png\" alt=\"Boxplots of predictors grouped by remission status\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<h2>Analysis methods you might consider<\/h2>\n<p>Below is a list of analysis methods you may have considered.<\/p>\n<ul>\n<li>Mixed effects logistic regression, the focus of this page.<\/li>\n<li>Mixed effects probit regression is very similar to mixed\neffects logistic regression, but it uses the normal CDF instead\nof the logistic CDF. Both model binary outcomes and can include\nfixed and random effects.<\/li>\n<li>Fixed effects logistic regression is limited in this case\nbecause it may ignore necessary random effects and\/or non\nindependence in the data.<\/li>\n<li>Fixed effects probit regression is limited in this case because\nit may ignore necessary random effects and\/or non independence in the data.<\/li>\n<li>Logistic regression with clustered standard errors. These can adjust\nfor non independence but does not allow for random effects.<\/li>\n<li>Probit regression with clustered standard errors. These can adjust\nfor non independence but does not allow for random effects.<\/li>\n<\/ul>\n<h2>Mixed effects logistic regression<\/h2>\n<p>Below we use the <code>glmer<\/code> command to estimate a mixed effects\nlogistic regression model with <code>Il6<\/code>, <code>CRP<\/code>, and\n<code>LengthofStay<\/code> as patient level continuous predictors,\n<code>CancerStage<\/code> as a patient level categorical predictor (I, II, III, or IV),\n<code>Experience<\/code> as a doctor level continuous predictor,\nand a random intercept by <code>DID<\/code>, doctor ID.<\/p>\n<p>Estimating and interpreting generalized linear mixed models\n(GLMMs, of which mixed effects logistic regression is one) can be quite\nchallenging. If you are just starting, we highly recommend reading this\npage first <a href=\"https:\/\/stats.idre.ucla.edu\/other\/mult-pkg\/introduction-to-generalized-linear-mixed-models\/\">Introduction to GLMMs <\/a>.\nIt covers some of the background and theory as well as estimation options,\ninference, and pitfalls in more detail.<\/p>\n<div id=\"unnamed-chunk-7\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># estimate the model and store results in m<\/span>\r\n<span class=\"hl std\">m<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">glmer<\/span><span class=\"hl std\">(remission<\/span> <span class=\"hl opt\">~<\/span> <span class=\"hl std\">IL6<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">CRP<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">CancerStage<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">LengthofStay<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">Experience<\/span> <span class=\"hl opt\">+<\/span>\r\n    <span class=\"hl std\">(<\/span><span class=\"hl num\">1<\/span> <span class=\"hl opt\">|<\/span> <span class=\"hl std\">DID),<\/span> <span class=\"hl kwc\">data<\/span> <span class=\"hl std\">= hdp,<\/span> <span class=\"hl kwc\">family<\/span> <span class=\"hl std\">= binomial,<\/span> <span class=\"hl kwc\">control<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">glmerControl<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">optimizer<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"bobyqa\"<\/span><span class=\"hl std\">),<\/span>\r\n    <span class=\"hl kwc\">nAGQ<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">10<\/span><span class=\"hl std\">)<\/span>\r\n\r\n<span class=\"hl com\"># print the mod results without correlations among fixed effects<\/span>\r\n<span class=\"hl kwd\">print<\/span><span class=\"hl std\">(m,<\/span> <span class=\"hl kwc\">corr<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">FALSE<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## Generalized linear mixed model fit by maximum likelihood (Adaptive\r\n##   Gauss-Hermite Quadrature, nAGQ = 10) [glmerMod]\r\n##  Family: binomial ( logit )\r\n## Formula: \r\n## remission ~ IL6 + CRP + CancerStage + LengthofStay + Experience +  \r\n##     (1 | DID)\r\n##    Data: hdp\r\n##      AIC      BIC   logLik deviance df.resid \r\n##     7397     7461    -3690     7379     8516 \r\n## Random effects:\r\n##  Groups Name        Std.Dev.\r\n##  DID    (Intercept) 2.01    \r\n## Number of obs: 8525, groups: DID, 407\r\n## Fixed Effects:\r\n##    (Intercept)             IL6             CRP   CancerStageII  \r\n##        -2.0527         -0.0568         -0.0215         -0.4139  \r\n## CancerStageIII   CancerStageIV    LengthofStay      Experience  \r\n##        -1.0035         -2.3370         -0.1212          0.1201\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>The first part tells us the estimates are based on an\nadaptive Gaussian Hermite approximation of the likelihood. In particular we used 10\nintegration points. As we use more\nintegration points, the approximation becomes more accurate converging to the ML estimates;\nhowever, more points are more computationally demanding and can be extremely slow\nor even intractable with today&#8217;s technology. To avoid a warning of nonconvergence, we specify a different optimizer with the argument <code>control=glmerControl(optimizer=\"bobyqa\")<\/code>. Although the model will produce nearly identical results without the new argument, we prefer to use models without such warnings.<\/p>\n<p>The next section gives us basic information that can be used to compare models,\nfollowed by the random effect estimates. This represents the estimated variability\nin the intercept on the logit scale. Had there been other random effects, such as\nrandom slopes, they would also appear here. The top section concludes with the\ntotal number of observations, and the number of level 2 observations. In our case,\nthis includes the total number of patients (8,525) and doctors (407).<\/p>\n<p>The last section is a table of the fixed effects estimates. For many applications,\nthese are what people are primarily interested in. The estimates represent the\nregression coefficients. These are unstandardized and are on the logit scale. The\nestimates are followed by their standard errors (SEs). As is common in GLMs, the SEs\nare obtained by inverting the observed information matrix (negative second derivative matrix).\nHowever, for GLMMs, this is again an approximation. The approximations of the coefficient\nestimates likely stabilize faster than do those for the SEs. Thus if you are using fewer\nintegration points, the estimates may be reasonable, but the approximation of the SEs may be\nless accurate. The Wald tests, (frac{Estimate}{SE}), rely on asymptotic theory, here referring\nto as the highest level unit size converges to infinity, these tests will be normally distributed,\nand from that, p values (the probability of obtaining the observed estimate or more extreme,\ngiven the true estimate is 0).<\/p>\n<p>It can be nice to get confidence intervals (CIs). We can get rough estimates using the SEs.<\/p>\n<div id=\"unnamed-chunk-8\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">se<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">sqrt<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">diag<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">vcov<\/span><span class=\"hl std\">(m)))<\/span>\r\n<span class=\"hl com\"># table of estimates with 95% CI<\/span>\r\n<span class=\"hl std\">(tab<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">cbind<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">Est<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">fixef<\/span><span class=\"hl std\">(m),<\/span> <span class=\"hl kwc\">LL<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">fixef<\/span><span class=\"hl std\">(m)<\/span> <span class=\"hl opt\">-<\/span> <span class=\"hl num\">1.96<\/span> <span class=\"hl opt\">*<\/span> <span class=\"hl std\">se,<\/span> <span class=\"hl kwc\">UL<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">fixef<\/span><span class=\"hl std\">(m)<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl num\">1.96<\/span> <span class=\"hl opt\">*<\/span>\r\n    <span class=\"hl std\">se))<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##                     Est       LL        UL\r\n## (Intercept)    -2.05269 -3.09435 -1.011025\r\n## IL6            -0.05677 -0.07935 -0.034196\r\n## CRP            -0.02148 -0.04151 -0.001455\r\n## CancerStageII  -0.41393 -0.56243 -0.265436\r\n## CancerStageIII -1.00346 -1.19610 -0.810828\r\n## CancerStageIV  -2.33704 -2.64683 -2.027241\r\n## LengthofStay   -0.12118 -0.18710 -0.055261\r\n## Experience      0.12009  0.06628  0.173895\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>If we wanted odds ratios instead of coefficients on the logit scale,\nwe could exponentiate the estimates and CIs.<\/p>\n<div id=\"unnamed-chunk-9\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">exp<\/span><span class=\"hl std\">(tab)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##                    Est      LL     UL\r\n## (Intercept)    0.12839 0.04530 0.3638\r\n## IL6            0.94481 0.92372 0.9664\r\n## CRP            0.97875 0.95934 0.9985\r\n## CancerStageII  0.66104 0.56982 0.7669\r\n## CancerStageIII 0.36661 0.30237 0.4445\r\n## CancerStageIV  0.09661 0.07088 0.1317\r\n## LengthofStay   0.88587 0.82936 0.9462\r\n## Experience     1.12760 1.06853 1.1899\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<h2>Multilevel bootstrapping<\/h2>\n<p>Inference from GLMMs is complicated. Except for cases where there are\nmany observations at each level (particularly the highest), assuming\nthat (frac{Estimate}{SE}) is normally distributed may not be accurate.\nA variety of alternatives have been suggested including Monte Carlo simulation,\nBayesian estimation, and bootstrapping. Each of these can be complex to\nimplement. We are going to focus on a small bootstrapping example.<\/p>\n<p>Bootstrapping is a resampling method. It is by no means perfect,\nbut it is conceptually straightforward and easy to implement in code.\nOne downside is that it is computationally demanding. For large datasets\nor complex models where each model takes minutes to run, estimating\non thousands of bootstrap samples can easily take hours or days. In the example\nfor this page, we use a very small number of samples, but in practice you\nwould use many more. Perhaps 1,000 is a reasonable starting point.<\/p>\n<p>For single level models, we can implement a simple random sample\nwith replacement for bootstrapping. With multilevel data, we want\nto resample in the same way as the data generating mechanism. We start\nby resampling from the highest level, and then stepping down one level\nat a time. In our case, we first will sample from doctors, and then\nwithin each doctor sampled, we will sample from their patients. To do this,\nwe first need to write a function to resample at each level.<\/p>\n<p>The Biostatistics Department at Vanderbilt has a nice page describing the idea:\u00a0<a href=\"https:\/\/biostat.app.vumc.org\/wiki\/Main\/HowToBootstrapCorrelatedData\">Applied Nonparametric Bootstrap with Hierarchical and Correlated Data<\/a><\/p>\n<div id=\"unnamed-chunk-10\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">sampler<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">dat<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">clustervar<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">replace<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">TRUE<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">reps<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">1<\/span><span class=\"hl std\">) {<\/span>\r\n    <span class=\"hl std\">cid<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">unique<\/span><span class=\"hl std\">(dat[, clustervar[<\/span><span class=\"hl num\">1<\/span><span class=\"hl std\">]])<\/span>\r\n    <span class=\"hl std\">ncid<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">length<\/span><span class=\"hl std\">(cid)<\/span>\r\n    <span class=\"hl std\">recid<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">sample<\/span><span class=\"hl std\">(cid,<\/span> <span class=\"hl kwc\">size<\/span> <span class=\"hl std\">= ncid<\/span> <span class=\"hl opt\">*<\/span> <span class=\"hl std\">reps,<\/span> <span class=\"hl kwc\">replace<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">TRUE<\/span><span class=\"hl std\">)<\/span>\r\n    <span class=\"hl kwa\">if<\/span> <span class=\"hl std\">(replace) {<\/span>\r\n        <span class=\"hl std\">rid<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">lapply<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">seq_along<\/span><span class=\"hl std\">(recid),<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">i<\/span><span class=\"hl std\">) {<\/span>\r\n            <span class=\"hl kwd\">cbind<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">NewID<\/span> <span class=\"hl std\">= i,<\/span> <span class=\"hl kwc\">RowID<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">sample<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">which<\/span><span class=\"hl std\">(dat[, clustervar]<\/span> <span class=\"hl opt\">==<\/span> <span class=\"hl std\">recid[i]),<\/span>\r\n                <span class=\"hl kwc\">size<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">length<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">which<\/span><span class=\"hl std\">(dat[, clustervar]<\/span> <span class=\"hl opt\">==<\/span> <span class=\"hl std\">recid[i])),<\/span> <span class=\"hl kwc\">replace<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">TRUE<\/span><span class=\"hl std\">))<\/span>\r\n        <span class=\"hl std\">})<\/span>\r\n    <span class=\"hl std\">}<\/span> <span class=\"hl kwa\">else<\/span> <span class=\"hl std\">{<\/span>\r\n        <span class=\"hl std\">rid<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">lapply<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">seq_along<\/span><span class=\"hl std\">(recid),<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">i<\/span><span class=\"hl std\">) {<\/span>\r\n            <span class=\"hl kwd\">cbind<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">NewID<\/span> <span class=\"hl std\">= i,<\/span> <span class=\"hl kwc\">RowID<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">which<\/span><span class=\"hl std\">(dat[, clustervar]<\/span> <span class=\"hl opt\">==<\/span> <span class=\"hl std\">recid[i]))<\/span>\r\n        <span class=\"hl std\">})<\/span>\r\n    <span class=\"hl std\">}<\/span>\r\n    <span class=\"hl std\">dat<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">as.data.frame<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">do.call<\/span><span class=\"hl std\">(rbind, rid))<\/span>\r\n    <span class=\"hl std\">dat<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">Replicate<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">cut<\/span><span class=\"hl std\">(dat<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">NewID,<\/span> <span class=\"hl kwc\">breaks<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">1<\/span><span class=\"hl std\">, ncid<\/span> <span class=\"hl opt\">*<\/span> <span class=\"hl num\">1<\/span><span class=\"hl opt\">:<\/span><span class=\"hl std\">reps),<\/span> <span class=\"hl kwc\">include.lowest<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">TRUE<\/span><span class=\"hl std\">,<\/span>\r\n        <span class=\"hl kwc\">labels<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">FALSE<\/span><span class=\"hl std\">))<\/span>\r\n    <span class=\"hl std\">dat<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">NewID<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(dat<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">NewID)<\/span>\r\n    <span class=\"hl kwd\">return<\/span><span class=\"hl std\">(dat)<\/span>\r\n<span class=\"hl std\">}<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>Now we will resample our data and take 100 replicates. Again in\npractice you would probably take thousands. We set the seed so that\nour results are reproducible. It is also likely that you will\nneed to sample more replicates than you ultimately want because many\nsamples may not converge so you do not get estimates from them.<\/p>\n<div id=\"unnamed-chunk-11\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">set.seed<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">20<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl std\">tmp<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">sampler<\/span><span class=\"hl std\">(hdp,<\/span> <span class=\"hl str\">\"DID\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">reps<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">100<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl std\">bigdata<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">cbind<\/span><span class=\"hl std\">(tmp, hdp[tmp<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">RowID, ])<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>Next we refit the model on the resampled data. First we store the\nestimates from our original model, which we will use as start values\nfor the bootstrap models. Then we make a local cluster with 4 nodes\n(the number of processors on our machine; set to the number of\nprocessors you have on yours). Next, we export the data and load\nthe <code>lme4<\/code> package on the cluster. Finally,\nwe write a function to fit the model and return the estimates.\nThe call to <code>glmer()<\/code> is wrapped in <code>try<\/code>\nbecause not all models may converge on the resampled data.\nThis catches the error and returns it, rather than stopping processing.<\/p>\n<div id=\"unnamed-chunk-12\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">f<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">fixef<\/span><span class=\"hl std\">(m)<\/span>\r\n<span class=\"hl std\">r<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">getME<\/span><span class=\"hl std\">(m,<\/span> <span class=\"hl str\">\"theta\"<\/span><span class=\"hl std\">)<\/span>\r\n\r\n<span class=\"hl std\">cl<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">makeCluster<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">4<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl kwd\">clusterExport<\/span><span class=\"hl std\">(cl,<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"bigdata\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"f\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"r\"<\/span><span class=\"hl std\">))<\/span>\r\n<span class=\"hl kwd\">clusterEvalQ<\/span><span class=\"hl std\">(cl,<\/span> <span class=\"hl kwd\">require<\/span><span class=\"hl std\">(lme4))<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## [[1]]\r\n## [1] TRUE\r\n## \r\n## [[2]]\r\n## [1] TRUE\r\n## \r\n## [[3]]\r\n## [1] TRUE\r\n## \r\n## [[4]]\r\n## [1] TRUE\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">myboot<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">i<\/span><span class=\"hl std\">) {<\/span>\r\n    <span class=\"hl std\">object<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">try<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">glmer<\/span><span class=\"hl std\">(remission<\/span> <span class=\"hl opt\">~<\/span> <span class=\"hl std\">IL6<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">CRP<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">CancerStage<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">LengthofStay<\/span> <span class=\"hl opt\">+<\/span>\r\n        <span class=\"hl std\">Experience<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">(<\/span><span class=\"hl num\">1<\/span> <span class=\"hl opt\">|<\/span> <span class=\"hl std\">NewID),<\/span> <span class=\"hl kwc\">data<\/span> <span class=\"hl std\">= bigdata,<\/span> <span class=\"hl kwc\">subset<\/span> <span class=\"hl std\">= Replicate<\/span> <span class=\"hl opt\">==<\/span> <span class=\"hl std\">i,<\/span> <span class=\"hl kwc\">family<\/span> <span class=\"hl std\">= binomial,<\/span>\r\n        <span class=\"hl kwc\">nAGQ<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">1<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">start<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">list<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">fixef<\/span> <span class=\"hl std\">= f,<\/span> <span class=\"hl kwc\">theta<\/span> <span class=\"hl std\">= r)),<\/span> <span class=\"hl kwc\">silent<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">TRUE<\/span><span class=\"hl std\">)<\/span>\r\n    <span class=\"hl kwa\">if<\/span> <span class=\"hl std\">(<\/span><span class=\"hl kwd\">class<\/span><span class=\"hl std\">(object)<\/span> <span class=\"hl opt\">==<\/span> <span class=\"hl str\">\"try-error\"<\/span><span class=\"hl std\">)<\/span>\r\n        <span class=\"hl kwd\">return<\/span><span class=\"hl std\">(object)<\/span>\r\n    <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">fixef<\/span><span class=\"hl std\">(object),<\/span> <span class=\"hl kwd\">getME<\/span><span class=\"hl std\">(object,<\/span> <span class=\"hl str\">\"theta\"<\/span><span class=\"hl std\">))<\/span>\r\n<span class=\"hl std\">}<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>Now that we have the data, the local cluster, and the fitting\nfunction setup, we are ready to actually do the bootstrapping.\nTo do this, we use the <code>parLapplyLB<\/code> function, which\nloops through every replicate, giving them out to each node of\nthe cluster to estimate the models. The &#8220;LB&#8221; stands for load\nbalancing, which means replicates are distributed as a node completes\nits current job. This is valuable because not all replicates will\nconverge, and if there is an error and it happens early on,\none node may be ready for a new job faster than another node.\nThere is some extra communication overhead, but this is small\ncompared to the time it takes to fit each model.\nThe results from all nodes are aggregated back into\na single list, stored in the object <code>res<\/code>. Once that\nis done, we can shut down the local cluster, which terminates\nthe additional <code>R<\/code> instances and frees memory.<\/p>\n<div id=\"unnamed-chunk-13\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">start<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">proc.time<\/span><span class=\"hl std\">()<\/span>\r\n<span class=\"hl std\">res<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">parLapplyLB<\/span><span class=\"hl std\">(cl,<\/span> <span class=\"hl kwc\">X<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">levels<\/span><span class=\"hl std\">(bigdata<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">Replicate),<\/span> <span class=\"hl kwc\">fun<\/span> <span class=\"hl std\">= myboot)<\/span>\r\n<span class=\"hl std\">end<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">proc.time<\/span><span class=\"hl std\">()<\/span>\r\n\r\n<span class=\"hl com\"># shut down the cluster<\/span>\r\n<span class=\"hl kwd\">stopCluster<\/span><span class=\"hl std\">(cl)<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>Now that we have the bootstrap results, we can summarize them.\nFirst, we calculate the number of models that successfully converged.\nWe do this by checking whether a particular result is numeric or not.\nErrors are not numeric, so they will be skipped. We can calculate the\nmean of the successes to see the proportion of replicates that converged\nand that we have results for.<\/p>\n<div id=\"unnamed-chunk-14\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># calculate proportion of models that successfully converged<\/span>\r\n<span class=\"hl std\">success<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">sapply<\/span><span class=\"hl std\">(res, is.numeric)<\/span>\r\n<span class=\"hl kwd\">mean<\/span><span class=\"hl std\">(success)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## [1] 1\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>Next we convert the list of bootstrap results\ninto a matrix, and then calculate the 2.5th and 97.5th percentiles\nfor each parameter. Finally, we can make a table of the results,\nincluding the original estimates and standard errors, the\nmean bootstrap estimate (which is asymptotically equivalent to\nthe original results, but may be biased for a small number of\nreplicates, as in our case), and the bootstrapped confidence\nintervals. With these data, you could also calculate bias-corrected\nbootstrap confidence intervals if you wanted, although we only\nshow the percentile CIs.<\/p>\n<div id=\"unnamed-chunk-15\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># combine successful results<\/span>\r\n<span class=\"hl std\">bigres<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">do.call<\/span><span class=\"hl std\">(cbind, res[success])<\/span>\r\n\r\n<span class=\"hl com\"># calculate 2.5th and 97.5th percentiles for 95% CI<\/span>\r\n<span class=\"hl std\">(ci<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">t<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">apply<\/span><span class=\"hl std\">(bigres,<\/span> <span class=\"hl num\">1<\/span><span class=\"hl std\">, quantile,<\/span> <span class=\"hl kwc\">probs<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">0.025<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">0.975<\/span><span class=\"hl std\">))))<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##                       2.5%     97.5%\r\n## (Intercept)       -3.61982 -0.985404\r\n## IL6               -0.08812 -0.029664\r\n## CRP               -0.04897  0.006824\r\n## CancerStageII     -0.60754 -0.228019\r\n## CancerStageIII    -1.30217 -0.754609\r\n## CancerStageIV     -2.91414 -2.002643\r\n## LengthofStay      -0.21596 -0.046420\r\n## Experience         0.06819  0.207223\r\n## NewID.(Intercept)  2.03868  2.476366\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># All results<\/span>\r\n<span class=\"hl std\">finaltable<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">cbind<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">Est<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(f, r),<\/span> <span class=\"hl kwc\">SE<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(se,<\/span> <span class=\"hl num\">NA<\/span><span class=\"hl std\">),<\/span> <span class=\"hl kwc\">BootMean<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">rowMeans<\/span><span class=\"hl std\">(bigres),<\/span>\r\n    <span class=\"hl std\">ci)<\/span>\r\n<span class=\"hl com\"># round and print<\/span>\r\n<span class=\"hl kwd\">round<\/span><span class=\"hl std\">(finaltable,<\/span> <span class=\"hl num\">3<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##                    Est    SE BootMean   2.5%  97.5%\r\n## (Intercept)     -2.053 0.531   -2.205 -3.620 -0.985\r\n## IL6             -0.057 0.012   -0.059 -0.088 -0.030\r\n## CRP             -0.021 0.010   -0.022 -0.049  0.007\r\n## CancerStageII   -0.414 0.076   -0.417 -0.608 -0.228\r\n## CancerStageIII  -1.003 0.098   -1.043 -1.302 -0.755\r\n## CancerStageIV   -2.337 0.158   -2.460 -2.914 -2.003\r\n## LengthofStay    -0.121 0.034   -0.142 -0.216 -0.046\r\n## Experience       0.120 0.027    0.128  0.068  0.207\r\n## DID.(Intercept)  2.015    NA    2.263  2.039  2.476\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<h2>Predicted probabilities and graphing<\/h2>\n<p>These results are great to put in the table or in the text of a\nresearch manuscript; however, the numbers can be tricky to interpret.\nVisual presentations are helpful to ease interpretation and for\nposters and presentations. As models become more complex, there are\nmany options. We will discuss some of them briefly and give an example\nhow you could do one.<\/p>\n<p>In a logistic model, the outcome is commonly on one of three scales:<\/p>\n<ul>\n<li>Log odds (also called logits), which is the linearized scale<\/li>\n<li>Odds ratios (exponentiated log odds), which are not on a linear scale<\/li>\n<li>Probabilities, which are also not on a linear scale<\/li>\n<\/ul>\n<p>For tables, people often present the odds ratios. For visualization,\nthe logit or probability scale is most common. There are some advantages\nand disadvantages to each. The logit scale is convenient because it is\nlinearized, meaning that a 1 unit increase in a predictor results in a\ncoefficient unit increase in the outcome and this holds regardless of the\nlevels of the other predictors (setting aside interactions for the moment).\nA downside is the scale is not very interpretable. It is hard for readers\nto have an intuitive understanding of logits. Conversely, probabilities are\na nice scale to intuitively understand the results; however, they are not\nlinear. This means that a one unit increase in the predictor, does not\nequal a constant increase in the probability&#8212;the change in probability\ndepends on the values chosen for the other predictors. In ordinary\nlogistic regression, you could just hold all predictors constant, only\nvarying your predictor of interest. However, in mixed effects logistic\nmodels, the random effects also bear on the results. Thus, if you hold\neverything constant, the change in probability of the outcome over\ndifferent values of your predictor of interest are only true when\nall covariates are held constant and you are in the same group, or a group\nwith the same random effect. The effects are conditional on other predictors\nand group membership, which is quite narrowing. An attractive alternative is\nto get the average marginal probability. That is, across all the groups in\nour sample (which is hopefully representative of your population of interest),\ngraph the <em>average<\/em> change in probability of the outcome across the\nrange of some predictor of interest.<\/p>\n<p>We are going to explore an example with average marginal probabilities.\nThese take more work than conditional probabilities, because you have to\ncalculate separate conditional probabilities for every group and then\naverage them. It is also not easy to get confidence intervals around\nthese average marginal effects in a frequentist framework (although\nthey are trivial to obtain from Bayesian estimation).<\/p>\n<p>First, let&#8217;s define the general procedure using the notation\nfrom <a href=\"https:\/\/stats.idre.ucla.edu\/other\/mult-pkg\/introduction-to-generalized-linear-mixed-models\/\">here <\/a>.\nWe create \\(\\mathbf{X}_{i}\\) by taking \\(\\mathbf{X}\\) and setting\na particular predictor of interest, say in column \\(j\\), to a constant.\nIf we only cared about one value of the predictor, \\(i \\in {1}\\).\nHowever, more commonly, we want a range of values for the predictor\nin order to plot how the predicted probability varies across its range.\nWe can do this by taking the observed range of the predictor and\ntaking \\(k\\) samples evenly spaced within the range. For example,\nsuppose our predictor ranged from 5 to 10, and we wanted 6 samples,\n\\(\\frac{10 &#8211; 5}{6 &#8211; 1} = 1\\), so each sample would be 1 apart from the\nprevious and they would be: \\({5, 6, 7, 8, 9, 10}\\). Then we create\n\\(k\\) different \\(\\mathbf{X}_{i}\\)s where \\(i \\in {1, \\ldots, k}\\)\nwhere in each case, the \\(j\\)th column is set to some constant. Then\nwe calculate:\n$$\n\\boldsymbol{\\eta}_{i} = \\mathbf{X}_{i}\\boldsymbol{\\beta} + \\mathbf{Z}\\boldsymbol{\\gamma}\n$$\nThese are all the different linear predictors. Finally, we take \\(h(\\boldsymbol{\\eta})\\),\nwhich gives us \\(\\boldsymbol{\\mu}_{i}\\), which are the conditional expectations\non the original scale, in our case, probabilities.\nWe can then take the expectation of each \\(\\boldsymbol{\\mu}_{i}\\) and plot\nthat against the value our predictor of interest was held at. We could also\nmake boxplots to show not only the average marginal predicted probability,\nbut also the distribution of predicted probabilities.<\/p>\n<p>You may have noticed that a lot of variability goes into those\nestimates. We are using \\(\\mathbf{X}\\) only holding our predictor of\ninterest at a constant, which allows all the other predictors to\ntake on values in the original data. Also, we have left\n\\(\\mathbf{Z}\\boldsymbol{\\gamma}\\) as in our sample, which means\nsome groups are more or less represented than others. If we had wanted,\nwe could have re-weighted all the groups to have equal weight. We chose\nto leave all these things as-is in this example based on the assumption\nthat our sample is truly a good representative of our population of\ninterest. Rather than attempt to pick meaningful values to hold\ncovariates at (even the mean is not necessarily meaningful, particularly\nif a covariate as a bimodal distribution, it may be that <em>no<\/em>\nparticipant had a value at or near the mean), we used the values from\nour sample. This also suggests that if our sample was a good\nrepresentation of the population, then the average marginal\npredicted probabilities are a good representation of the probability\nfor a new random sample from our population.<\/p>\n<p>Now that we have some background and theory, let&#8217;s\nsee how we actually go about calculating these things.\nWe get a summary of <code>LengthofStay<\/code>,\nour predictor of interest, and then get 100 values across its range\nto use in prediction. We make a\ncopy of our data so we can fix the values of one of the predictors\nand then use the <code>predict<\/code> function to calculate the\npredicted values. All random effects are included by default,\nsee <code>?predict.merMod<\/code> for more details.\n<strong>Note that the predict method for mixed effects models is new\nand currently is only in the development version of <code>lme4<\/code>,\nso make sure that you have that installed.<\/strong><\/p>\n<div id=\"unnamed-chunk-16\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># temporary data<\/span>\r\n<span class=\"hl std\">tmpdat<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl std\">hdp[,<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"IL6\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"CRP\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"CancerStage\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"LengthofStay\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"Experience\"<\/span><span class=\"hl std\">,<\/span>\r\n    <span class=\"hl str\">\"DID\"<\/span><span class=\"hl std\">)]<\/span>\r\n\r\n<span class=\"hl kwd\">summary<\/span><span class=\"hl std\">(hdp<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">LengthofStay)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n##    1.00    5.00    5.00    5.49    6.00   10.00\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl std\">jvalues<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">with<\/span><span class=\"hl std\">(hdp,<\/span> <span class=\"hl kwd\">seq<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">from<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">min<\/span><span class=\"hl std\">(LengthofStay),<\/span> <span class=\"hl kwc\">to<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">max<\/span><span class=\"hl std\">(LengthofStay),<\/span> <span class=\"hl kwc\">length.out<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">100<\/span><span class=\"hl std\">))<\/span>\r\n\r\n<span class=\"hl com\"># calculate predicted probabilities and store in a list<\/span>\r\n<span class=\"hl std\">pp<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">lapply<\/span><span class=\"hl std\">(jvalues,<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">j<\/span><span class=\"hl std\">) {<\/span>\r\n    <span class=\"hl std\">tmpdat<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">LengthofStay<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl std\">j<\/span>\r\n    <span class=\"hl kwd\">predict<\/span><span class=\"hl std\">(m,<\/span> <span class=\"hl kwc\">newdata<\/span> <span class=\"hl std\">= tmpdat,<\/span> <span class=\"hl kwc\">type<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"response\"<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl std\">})<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>Now that we have all the predicted probabilities,\nwe can work on displaying them. For example, we could\nlook at the average marginal predicted probability at\na handful of different lengths of stay. We can also\nplot all of them.<\/p>\n<div id=\"unnamed-chunk-17\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># average marginal predicted probability across a few different Lengths of<\/span>\r\n<span class=\"hl com\"># Stay<\/span>\r\n<span class=\"hl kwd\">sapply<\/span><span class=\"hl std\">(pp[<\/span><span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">1<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">20<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">40<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">60<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">80<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">100<\/span><span class=\"hl std\">)], mean)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## [1] 0.3652 0.3366 0.3075 0.2796 0.2530 0.2278\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># get the means with lower and upper quartiles<\/span>\r\n<span class=\"hl std\">plotdat<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">t<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">sapply<\/span><span class=\"hl std\">(pp,<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">x<\/span><span class=\"hl std\">) {<\/span>\r\n    <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">M<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">mean<\/span><span class=\"hl std\">(x),<\/span> <span class=\"hl kwd\">quantile<\/span><span class=\"hl std\">(x,<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">0.25<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">0.75<\/span><span class=\"hl std\">)))<\/span>\r\n<span class=\"hl std\">}))<\/span>\r\n\r\n<span class=\"hl com\"># add in LengthofStay values and convert to data frame<\/span>\r\n<span class=\"hl std\">plotdat<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">as.data.frame<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">cbind<\/span><span class=\"hl std\">(plotdat, jvalues))<\/span>\r\n\r\n<span class=\"hl com\"># better names and show the first few rows<\/span>\r\n<span class=\"hl kwd\">colnames<\/span><span class=\"hl std\">(plotdat)<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"PredictedProbability\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"Lower\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"Upper\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"LengthofStay\"<\/span><span class=\"hl std\">)<\/span>\r\n<span class=\"hl kwd\">head<\/span><span class=\"hl std\">(plotdat)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##   PredictedProbability   Lower  Upper LengthofStay\r\n## 1               0.3652 0.08490 0.6156        1.000\r\n## 2               0.3637 0.08405 0.6130        1.091\r\n## 3               0.3622 0.08320 0.6103        1.182\r\n## 4               0.3607 0.08237 0.6077        1.273\r\n## 5               0.3591 0.08154 0.6051        1.364\r\n## 6               0.3576 0.08072 0.6024        1.455\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># plot average marginal predicted probabilities<\/span>\r\n<span class=\"hl kwd\">ggplot<\/span><span class=\"hl std\">(plotdat,<\/span> <span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">x<\/span> <span class=\"hl std\">= LengthofStay,<\/span> <span class=\"hl kwc\">y<\/span> <span class=\"hl std\">= PredictedProbability))<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl kwd\">geom_line<\/span><span class=\"hl std\">()<\/span> <span class=\"hl opt\">+<\/span>\r\n    <span class=\"hl kwd\">ylim<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">0<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">1<\/span><span class=\"hl std\">))<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/melogit-unnamed-chunk-17.png\" alt=\"Average Marginal predicted probabilities plot\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<p>We could also add the lower and upper quartiles. This information shows\nus the range in which 50 percent of the predicted probabilities fell.<\/p>\n<div id=\"unnamed-chunk-18\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">ggplot<\/span><span class=\"hl std\">(plotdat,<\/span> <span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">x<\/span> <span class=\"hl std\">= LengthofStay,<\/span> <span class=\"hl kwc\">y<\/span> <span class=\"hl std\">= PredictedProbability))<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl kwd\">geom_linerange<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">ymin<\/span> <span class=\"hl std\">= Lower,<\/span>\r\n    <span class=\"hl kwc\">ymax<\/span> <span class=\"hl std\">= Upper))<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl kwd\">geom_line<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">size<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">2<\/span><span class=\"hl std\">)<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl kwd\">ylim<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">0<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">1<\/span><span class=\"hl std\">))<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/melogit-unnamed-chunk-18.png\" alt=\"Average Marginal predicted probabilities plot with lower and upper quartile bars\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<p>This is just the beginning of what can be done. For plots, it is\nuseful to add more information. We could make the same average marginal\npredicted probabilities, but in addition to varying <code>LengthofStay<\/code>\nwe could do it for each level of <code>CancerStage<\/code>.<\/p>\n<div id=\"unnamed-chunk-19\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># calculate predicted probabilities and store in a list<\/span>\r\n<span class=\"hl std\">biprobs<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">lapply<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">levels<\/span><span class=\"hl std\">(hdp<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">CancerStage),<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">stage<\/span><span class=\"hl std\">) {<\/span>\r\n  <span class=\"hl std\">tmpdat<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">CancerStage[]<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl std\">stage<\/span>\r\n  <span class=\"hl kwd\">lapply<\/span><span class=\"hl std\">(jvalues,<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">j<\/span><span class=\"hl std\">) {<\/span>\r\n    <span class=\"hl std\">tmpdat<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">LengthofStay<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl std\">j<\/span>\r\n    <span class=\"hl kwd\">predict<\/span><span class=\"hl std\">(m,<\/span> <span class=\"hl kwc\">newdata<\/span> <span class=\"hl std\">= tmpdat,<\/span> <span class=\"hl kwc\">type<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"response\"<\/span><span class=\"hl std\">)<\/span>\r\n  <span class=\"hl std\">})<\/span>\r\n<span class=\"hl std\">})<\/span>\r\n\r\n<span class=\"hl com\"># get means and quartiles for all jvalues for each level of CancerStage<\/span>\r\n<span class=\"hl std\">plotdat2<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">lapply<\/span><span class=\"hl std\">(biprobs,<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">X<\/span><span class=\"hl std\">) {<\/span>\r\n  <span class=\"hl std\">temp<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">t<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">sapply<\/span><span class=\"hl std\">(X,<\/span> <span class=\"hl kwa\">function<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">x<\/span><span class=\"hl std\">) {<\/span>\r\n    <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">M<\/span><span class=\"hl std\">=<\/span><span class=\"hl kwd\">mean<\/span><span class=\"hl std\">(x),<\/span> <span class=\"hl kwd\">quantile<\/span><span class=\"hl std\">(x,<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">.25<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">.75<\/span><span class=\"hl std\">)))<\/span>\r\n  <span class=\"hl std\">}))<\/span>\r\n  <span class=\"hl std\">temp<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">as.data.frame<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">cbind<\/span><span class=\"hl std\">(temp, jvalues))<\/span>\r\n  <span class=\"hl kwd\">colnames<\/span><span class=\"hl std\">(temp)<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl str\">\"PredictedProbability\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"Lower\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"Upper\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl str\">\"LengthofStay\"<\/span><span class=\"hl std\">)<\/span>\r\n  <span class=\"hl kwd\">return<\/span><span class=\"hl std\">(temp)<\/span>\r\n<span class=\"hl std\">})<\/span>\r\n\r\n<span class=\"hl com\"># collapse to one data frame<\/span>\r\n<span class=\"hl std\">plotdat2<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">do.call<\/span><span class=\"hl std\">(rbind, plotdat2)<\/span>\r\n\r\n<span class=\"hl com\"># add cancer stage<\/span>\r\n<span class=\"hl std\">plotdat2<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">CancerStage<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">factor<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">rep<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">levels<\/span><span class=\"hl std\">(hdp<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">CancerStage),<\/span> <span class=\"hl kwc\">each<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">length<\/span><span class=\"hl std\">(jvalues)))<\/span>\r\n\r\n<span class=\"hl com\"># show first few rows<\/span>\r\n<span class=\"hl kwd\">head<\/span><span class=\"hl std\">(plotdat2)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##   PredictedProbability  Lower  Upper LengthofStay CancerStage\r\n## 1               0.4475 0.1547 0.7328        1.000           I\r\n## 2               0.4458 0.1533 0.7307        1.091           I\r\n## 3               0.4441 0.1519 0.7285        1.182           I\r\n## 4               0.4425 0.1505 0.7263        1.273           I\r\n## 5               0.4408 0.1491 0.7241        1.364           I\r\n## 6               0.4391 0.1477 0.7219        1.455           I\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># graph it<\/span>\r\n<span class=\"hl kwd\">ggplot<\/span><span class=\"hl std\">(plotdat2,<\/span> <span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">x<\/span> <span class=\"hl std\">= LengthofStay,<\/span> <span class=\"hl kwc\">y<\/span> <span class=\"hl std\">= PredictedProbability))<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">geom_ribbon<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">ymin<\/span> <span class=\"hl std\">= Lower,<\/span> <span class=\"hl kwc\">ymax<\/span> <span class=\"hl std\">= Upper,<\/span> <span class=\"hl kwc\">fill<\/span> <span class=\"hl std\">= CancerStage),<\/span> <span class=\"hl kwc\">alpha<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">.15<\/span><span class=\"hl std\">)<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">geom_line<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">colour<\/span> <span class=\"hl std\">= CancerStage),<\/span> <span class=\"hl kwc\">size<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">2<\/span><span class=\"hl std\">)<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl kwd\">ylim<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">0<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">1<\/span><span class=\"hl std\">))<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl kwd\">facet_wrap<\/span><span class=\"hl std\">(<\/span><span class=\"hl opt\">~<\/span>  <span class=\"hl std\">CancerStage)<\/span>\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/melogit-unnamed-chunk-19.png\" alt=\"Average Marginal predicted probabilities plot with lower and upper quartile bars by cancer stage\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<p>Things look fairly bleak for the chances of a Stage IV lung cancer\npatient who was in the hospital 10 days having cancer in remission\n(please remember that these are simulated data).\nIt also looks like the distribution is skewed. We can examine the\ndistribution of predicted probabilities just for that group.<\/p>\n<div id=\"unnamed-chunk-20\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">ggplot<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">data.frame<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">Probs<\/span> <span class=\"hl std\">= biprobs[[<\/span><span class=\"hl num\">4<\/span><span class=\"hl std\">]][[<\/span><span class=\"hl num\">100<\/span><span class=\"hl std\">]]),<\/span> <span class=\"hl kwd\">aes<\/span><span class=\"hl std\">(Probs))<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl kwd\">geom_histogram<\/span><span class=\"hl std\">()<\/span> <span class=\"hl opt\">+<\/span>\r\n    <span class=\"hl kwd\">scale_x_sqrt<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">breaks<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">c<\/span><span class=\"hl std\">(<\/span><span class=\"hl num\">0.01<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">0.1<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">0.25<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">0.5<\/span><span class=\"hl std\">,<\/span> <span class=\"hl num\">0.75<\/span><span class=\"hl std\">))<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"message\">\n<pre class=\"knitr r\">## stat_bin: binwidth defaulted to range\/30. Use 'binwidth = x' to adjust this.\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/melogit-unnamed-chunk-20.png\" alt=\"Histogram of predicted probabilities for a 10 day stay with stage 4 cancer\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<p>Even using a square root scale that stretches out the lower\nvalues, it is still extremely skewed. The vast majority\nare estimated to have less than a .1 probability of being in\nremission.<\/p>\n<h2>Three level mixed effects logistic regression<\/h2>\n<p>We have looked at a two level logistic model with a random\nintercept in depth. This is the simplest mixed effects logistic model\npossible. Now we are going to briefly look at how you can add a third\nlevel and random slope effects as well as random intercepts.<\/p>\n<p>Below we estimate a three level logistic model with a random\nintercept for doctors and a random intercept for hospitals.\nIn this examples, doctors are <em>nested<\/em> within hospitals,\nmeaning that each doctor belongs to one and only one hospital.\nThe alternative case is sometimes called &#8220;cross classified&#8221;\nmeaning that a doctor may belong to multiple hospitals, such as\nif some of the doctor&#8217;s patients are from hospital A and others\nfrom hospital B. In <code>glmer<\/code> you do not need to specify\nwhether the groups are nested or cross classified, <code>R<\/code>\ncan figure it out based on the data. We use the same\n<code>(1 | ID)<\/code> general syntax to indicate the intercept (1)\nvarying by some ID. For models with more than a single\nscalar random effect, <code>glmer<\/code> only supports a single\nintegration point, so we use <code>nAGQ=1<\/code>.<\/p>\n<div id=\"unnamed-chunk-21\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># estimate the model and store results in m<\/span>\r\n<span class=\"hl std\">m3a<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">glmer<\/span><span class=\"hl std\">(remission<\/span> <span class=\"hl opt\">~<\/span> <span class=\"hl std\">Age<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">LengthofStay<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">FamilyHx<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">IL6<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">CRP<\/span> <span class=\"hl opt\">+<\/span>\r\n  <span class=\"hl std\">CancerStage<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">Experience<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">(<\/span><span class=\"hl num\">1<\/span> <span class=\"hl opt\">|<\/span> <span class=\"hl std\">DID)<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">(<\/span><span class=\"hl num\">1<\/span> <span class=\"hl opt\">|<\/span> <span class=\"hl std\">HID),<\/span>\r\n  <span class=\"hl kwc\">data<\/span> <span class=\"hl std\">= hdp,<\/span> <span class=\"hl kwc\">family<\/span> <span class=\"hl std\">= binomial,<\/span> <span class=\"hl kwc\">nAGQ<\/span><span class=\"hl std\">=<\/span><span class=\"hl num\">1<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"warning\">\n<pre class=\"knitr r\">## Warning: Model failed to converge with max|grad| = 74.1215 (tol = 0.001)\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># print the mod results without correlations among fixed effects<\/span>\r\n<span class=\"hl kwd\">print<\/span><span class=\"hl std\">(m3a,<\/span> <span class=\"hl kwc\">corr<\/span><span class=\"hl std\">=<\/span><span class=\"hl num\">FALSE<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## Generalized linear mixed model fit by maximum likelihood (Laplace\r\n##   Approximation) [glmerMod]\r\n##  Family: binomial ( logit )\r\n## Formula: \r\n## remission ~ Age + LengthofStay + FamilyHx + IL6 + CRP + CancerStage +  \r\n##     Experience + (1 | DID) + (1 | HID)\r\n##    Data: hdp\r\n##      AIC      BIC   logLik deviance df.resid \r\n##     7199     7284    -3588     7175     8513 \r\n## Random effects:\r\n##  Groups Name        Std.Dev.\r\n##  DID    (Intercept) 1.952   \r\n##  HID    (Intercept) 0.549   \r\n## Number of obs: 8525, groups: DID, 407; HID, 35\r\n## Fixed Effects:\r\n##    (Intercept)             Age    LengthofStay     FamilyHxyes  \r\n##        -1.6881         -0.0149         -0.0447         -1.3066  \r\n##            IL6             CRP   CancerStageII  CancerStageIII  \r\n##        -0.0569         -0.0222         -0.3185         -0.8570  \r\n##  CancerStageIV      Experience  \r\n##        -2.1375          0.1269\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>The output tells us the family (binomial for binary outcomes)\nand the link (logit). Followed by usual fit indices and the variance of the\nrandom effects. In this case the variability in the intercept (on the\nlog odds scale) between doctors and between hospitals. The standard deviation\nis also displayed (simply the square root of the variance, not the\nstandard error of the estimate of the variance). We also get the\nnumber of unique units at each level. Last are the fixed effects,\nas before.<\/p>\n<p>It can also be useful to look at the distribution of the\nconditional modes, which we do with caterpillar polots below.\nThe blue dots are the conditional models with error bars.\nWe do this for both doctors and hospitals. For example for\ndoctors, we can see a bit of a long right tail in that there\nare more extreme positive than negative values. For the\ndoctors, we suppress their IDs (using the\n<code>scales=list(y = list(alternating=0))<\/code> argument)\nbecause there are so many, but we leave them in for the hospitals.<\/p>\n<div id=\"unnamed-chunk-22\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">lattice::dotplot<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">ranef<\/span><span class=\"hl std\">(m3a,<\/span> <span class=\"hl kwc\">which<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"DID\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">condVar<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">TRUE<\/span><span class=\"hl std\">),<\/span> <span class=\"hl kwc\">scales<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">list<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">y<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">list<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">alternating<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">0<\/span><span class=\"hl std\">)))<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## $DID\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/melogit-unnamed-chunk-221.png\" alt=\"Caterpillar plot of conditional modes for intercept by doctor\" width=\"500px\" height=\"500px\" \/><\/div>\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">lattice::dotplot<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">ranef<\/span><span class=\"hl std\">(m3a,<\/span> <span class=\"hl kwc\">which<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"HID\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">condVar<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">TRUE<\/span><span class=\"hl std\">))<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## $HID\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/melogit-unnamed-chunk-222.png\" alt=\"Caterpillar plot of conditional modes for intercept by hospital\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<p>We can easily add random slopes to the model as well,\nand allow them to vary at any level. We are just going to\nadd a random slope for <code>LengthofStay<\/code> that\nvaries between doctors. As in regular <code>R<\/code>\nformulae, we use the <code>+<\/code> operator to &#8220;add&#8221;\nan effect, and we do it in the section for doctor random\neffects. All terms in one group of parentheses use an\nunstructured covariance matrix, you can get a diagonal\ncovariance structure by splitting the grouping into\nseparate pieces. Between groupings is assumed indepedent.<\/p>\n<div id=\"unnamed-chunk-23\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># estimate the model and store results in m<\/span>\r\n<span class=\"hl std\">m3b<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">glmer<\/span><span class=\"hl std\">(remission<\/span> <span class=\"hl opt\">~<\/span> <span class=\"hl std\">Age<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">LengthofStay<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">FamilyHx<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">IL6<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">CRP<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">CancerStage<\/span> <span class=\"hl opt\">+<\/span>\r\n    <span class=\"hl std\">Experience<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">(<\/span><span class=\"hl num\">1<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">LengthofStay<\/span> <span class=\"hl opt\">|<\/span> <span class=\"hl std\">DID)<\/span> <span class=\"hl opt\">+<\/span> <span class=\"hl std\">(<\/span><span class=\"hl num\">1<\/span> <span class=\"hl opt\">|<\/span> <span class=\"hl std\">HID),<\/span> <span class=\"hl kwc\">data<\/span> <span class=\"hl std\">= hdp,<\/span> <span class=\"hl kwc\">family<\/span> <span class=\"hl std\">= binomial,<\/span>\r\n    <span class=\"hl kwc\">nAGQ<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">1<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"warning\">\n<pre class=\"knitr r\">## Warning: Model failed to converge with max|grad| = 34.9006 (tol = 0.001)\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl com\"># print the mod results without correlations among fixed effects<\/span>\r\n<span class=\"hl kwd\">print<\/span><span class=\"hl std\">(m3b,<\/span> <span class=\"hl kwc\">corr<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">FALSE<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## Generalized linear mixed model fit by maximum likelihood (Laplace\r\n##   Approximation) [glmerMod]\r\n##  Family: binomial ( logit )\r\n## Formula: \r\n## remission ~ Age + LengthofStay + FamilyHx + IL6 + CRP + CancerStage +  \r\n##     Experience + (1 + LengthofStay | DID) + (1 | HID)\r\n##    Data: hdp\r\n##      AIC      BIC   logLik deviance df.resid \r\n##     7148     7246    -3560     7120     8511 \r\n## Random effects:\r\n##  Groups Name         Std.Dev. Corr \r\n##  DID    (Intercept)  0.504         \r\n##         LengthofStay 0.372    -0.11\r\n##  HID    (Intercept)  0.731         \r\n## Number of obs: 8525, groups: DID, 407; HID, 35\r\n## Fixed Effects:\r\n##    (Intercept)             Age    LengthofStay     FamilyHxyes  \r\n##        -0.5447         -0.0152         -0.1901         -1.3395  \r\n##            IL6             CRP   CancerStageII  CancerStageIII  \r\n##        -0.0586         -0.0210         -0.2941         -0.8651  \r\n##  CancerStageIV      Experience  \r\n##        -2.2964          0.1044\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<div id=\"unnamed-chunk-24\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">lattice::dotplot<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">ranef<\/span><span class=\"hl std\">(m3b,<\/span> <span class=\"hl kwc\">which<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"DID\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">condVar<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">TRUE<\/span><span class=\"hl std\">),<\/span> <span class=\"hl kwc\">scales<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">list<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">y<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">list<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">alternating<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">0<\/span><span class=\"hl std\">)))<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## $DID\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/melogit-unnamed-chunk-241.png\" alt=\"Caterpillar plot of conditional modes of random intercepts and random LengthofStay slopes by doctor\" width=\"500px\" height=\"500px\" \/><\/div>\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">lattice::dotplot<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwd\">ranef<\/span><span class=\"hl std\">(m3b,<\/span> <span class=\"hl kwc\">which<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"HID\"<\/span><span class=\"hl std\">,<\/span> <span class=\"hl kwc\">condVar<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">TRUE<\/span><span class=\"hl std\">),<\/span> <span class=\"hl kwc\">scales<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">list<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">y<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl kwd\">list<\/span><span class=\"hl std\">(<\/span><span class=\"hl kwc\">alternating<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl num\">0<\/span><span class=\"hl std\">)))<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## $HID\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/melogit-unnamed-chunk-242.png\" alt=\"Caterpillar plot of conditional modes of random intercpets by hospital\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<h2>Things to consider<\/h2>\n<p>See\nthe <a href=\"\/mult_pkg\/glmm.htm#issues\">Other\nIssues<\/a> section of the introduction to GLMMs page for some\nconsiderations and issues.<\/p>\n<h2>See also<\/h2>\n<ul>\n<li><a href=\"https:\/\/stats.idre.ucla.edu\/other\/mult-pkg\/introduction-to-generalized-linear-mixed-models\/\">Introduction to GLMMs<\/a><\/li>\n<li><a href=\"\/r\/dae\/logit-regression\/\">Regular Logistic Regression in R<\/a><\/li>\n<\/ul>\n<h2>References<\/h2>\n<ul>\n<li>Agresti, A. (2013). <i>Categorical Data Analysis<\/i> (3rd Ed.),\nHoboken, New Jersey: John Wiley &amp; Sons.<\/li>\n<\/ul>\n","protected":false},"excerpt":{"rendered":"<p>Mixed effects logistic regression is used to model binary outcome variables, in which the log odds of the outcomes are modeled as a linear combination of the predictor variables when&#8230;<br><a class=\"moretag\" href=\"https:\/\/stats.oarc.ucla.edu\/r\/dae\/mixed-effects-logistic-regression\/\"> Read More<\/a><\/p>\n","protected":false},"author":1,"featured_media":0,"parent":916,"menu_order":6,"comment_status":"closed","ping_status":"closed","template":"","meta":{"_genesis_hide_title":false,"_genesis_hide_breadcrumbs":false,"_genesis_hide_singular_image":false,"_genesis_hide_footer_widgets":false,"_genesis_custom_body_class":"","_genesis_custom_post_class":"","_genesis_layout":"","footnotes":""},"class_list":["post-924","page","type-page","status-publish","entry"],"_links":{"self":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/924","targetHints":{"allow":["GET"]}}],"collection":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/comments?post=924"}],"version-history":[{"count":26,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/924\/revisions"}],"predecessor-version":[{"id":35796,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/924\/revisions\/35796"}],"up":[{"embeddable":true,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/916"}],"wp:attachment":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/media?parent=924"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}