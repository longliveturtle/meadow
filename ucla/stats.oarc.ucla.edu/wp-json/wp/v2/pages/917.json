{"id":917,"date":"2016-02-11T18:29:03","date_gmt":"2016-02-11T18:29:03","guid":{"rendered":"http:\/\/dev2.hpc.ucla.edu\/r\/dae\/r-data-analysis-examples-canonical-correlation-analysis\/"},"modified":"2023-09-06T12:07:34","modified_gmt":"2023-09-06T19:07:34","slug":"canonical-correlation-analysis","status":"publish","type":"page","link":"https:\/\/stats.oarc.ucla.edu\/r\/dae\/canonical-correlation-analysis\/","title":{"rendered":"Canonical Correlation Analysis |  R Data Analysis Examples"},"content":{"rendered":"<p><!--?php include \"stat\/header.htm\"; ?--><\/p>\n<p>Canonical correlation analysis is used to\nidentify and measure the associations among two sets of variables.\nCanonical correlation is appropriate in the same situations where multiple\nregression would be, but where are there are multiple intercorrelated outcome\nvariables. Canonical correlation analysis determines a set of canonical variates,\northogonal linear combinations of the variables within each set that best\nexplain the variability both within and between sets.<\/p>\n<p>This page uses the following packages. Make sure that you can load\nthem before trying to run the examples on this page. If you do not have\na package installed, run: <code>install.packages(\"packagename\")<\/code>, or\nif you see the version is out of date, run: <code>update.packages()<\/code>.<\/p>\n<div class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"functioncall\">require<\/span>(ggplot2)\r\n<span class=\"functioncall\">require<\/span>(GGally)\r\n<span class=\"functioncall\">require<\/span>(CCA)\r\n<span class=\"functioncall\">require<\/span>(CCP)\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p><code class=\"knitr inline\"><b>Version info: <\/b>Code for this page was tested in R Under development (unstable) (2012-11-16 r61126)\nOn: 2012-12-15\nWith: CCP 1.1; CCA 1.2; fields 6.7; spam 0.29-2; fda 2.3.2; RCurl 1.95-3; bitops 1.0-5; Matrix 1.0-10; lattice 0.20-10; zoo 1.7-9; GGally 0.4.2; reshape 0.8.4; plyr 1.8; ggplot2 0.9.3; knitr 0.9\n<\/code><\/p>\n<p><strong>Please Note:<\/strong> The purpose of this page is to show how to use various data analysis commands.\nIt does not cover all aspects of the research process which researchers are expected to do. In\nparticular, it does not cover data cleaning and checking, verification of assumptions, model\ndiagnostics and potential follow-up analyses.<\/p>\n<h2>Examples of canonical correlation analysis<\/h2>\n<p>Example 1. A researcher has collected data on three psychological variables, four academic variables\n(standardized test scores) and gender for 600 college freshman. She is interested in\nhow the set of psychological variables relates to the academic variables and gender. In\nparticular, the researcher is interested in how many dimensions (canonical\nvariables) are necessary to understand\nthe association between the two sets of variables.<\/p>\n<p>Example 2. A researcher is interested in exploring associations among factors from two multidimensional\npersonality tests, the MMPI and the NEO. She is interested in what dimensions\nare common between the tests and how much\nvariance is shared between them. She is specifically interested in finding\nwhether the neuroticism dimension from the NEO can account for a substantial amount of shared variance\nbetween the two tests.<\/p>\n<h2>Description of the data<\/h2>\n<p>For our analysis example, we are going to expand example 1 about investigating\nthe associations between psychological measures and academic achievement\nmeasures.<\/p>\n<p>We have a data file, <strong>mmreg.dta<\/strong>, with 600 observations on eight variables.\nThe psychological variables are <code>locus_of_control<\/code>, <code>self_concept<\/code> and\n<code>motivation<\/code>. The academic variables are standardized tests in\nreading (<code>read<\/code>), writing (<code>write<\/code>),\nmath (<code>math<\/code>) and science (<code>science<\/code>). Additionally,\nthe variable <code>female<\/code> is a zero-one indicator variable\nwith the one indicating a female student.<\/p>\n<div class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\">mm &lt;- <span class=\"functioncall\">read.csv<\/span>(<span class=\"string\">\"https:\/\/stats.idre.ucla.edu\/stat\/data\/mmreg.csv\"<\/span>)\r\n<span class=\"functioncall\">colnames<\/span>(mm) &lt;- <span class=\"functioncall\">c<\/span>(<span class=\"string\">\"Control\"<\/span>, <span class=\"string\">\"Concept\"<\/span>, <span class=\"string\">\"Motivation\"<\/span>, <span class=\"string\">\"Read\"<\/span>, <span class=\"string\">\"Write\"<\/span>, <span class=\"string\">\"Math\"<\/span>, \r\n    <span class=\"string\">\"Science\"<\/span>, <span class=\"string\">\"Sex\"<\/span>)\r\n<span class=\"functioncall\">summary<\/span>(mm)\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##     Control           Concept          Motivation         Read     \r\n##  Min.   :-2.2300   Min.   :-2.6200   Min.   :0.000   Min.   :28.3  \r\n##  1st Qu.:-0.3725   1st Qu.:-0.3000   1st Qu.:0.330   1st Qu.:44.2  \r\n##  Median : 0.2100   Median : 0.0300   Median :0.670   Median :52.1  \r\n##  Mean   : 0.0965   Mean   : 0.0049   Mean   :0.661   Mean   :51.9  \r\n##  3rd Qu.: 0.5100   3rd Qu.: 0.4400   3rd Qu.:1.000   3rd Qu.:60.1  \r\n##  Max.   : 1.3600   Max.   : 1.1900   Max.   :1.000   Max.   :76.0  \r\n##      Write           Math         Science          Sex       \r\n##  Min.   :25.5   Min.   :31.8   Min.   :26.0   Min.   :0.000  \r\n##  1st Qu.:44.3   1st Qu.:44.5   1st Qu.:44.4   1st Qu.:0.000  \r\n##  Median :54.1   Median :51.3   Median :52.6   Median :1.000  \r\n##  Mean   :52.4   Mean   :51.9   Mean   :51.8   Mean   :0.545  \r\n##  3rd Qu.:59.9   3rd Qu.:58.4   3rd Qu.:58.6   3rd Qu.:1.000  \r\n##  Max.   :67.1   Max.   :75.5   Max.   :74.2   Max.   :1.000\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<h2>Analysis methods you might consider<\/h2>\n<p>Below is a list of some analysis methods you may have encountered.\nSome of the methods listed are quite reasonable while others have either\nfallen out of favor or have limitations.<\/p>\n<ul>\n<li>Canonical correlation analysis, the focus of this page.<\/li>\n<li>Separate OLS Regressions &#8211; You could analyze these data using separate OLS regression\nanalyses for each variable in one set. The OLS regressions\nwill not produce multivariate results and does not report information\nconcerning dimensionality.<\/li>\n<li>Multivariate multiple regression is a reasonable option if you have\nno interest in dimensionality.<\/li>\n<\/ul>\n<h2>Canonical correlation analysis<\/h2>\n<p>Below we use the <code>canon<\/code> command to conduct a canonical correlation\nanalysis. It requires two sets of variables enclosed with a pair of\nparentheses. We specify our psychological variables as the first set of\nvariables and our academic variables plus gender as the second set. For\nconvenience, the variables in the first set are called &#8220;u&#8221; variables and the\nvariables in the second set are called &#8220;v&#8221; variables.<\/p>\n<p>Let&#8217;s look at the data.<\/p>\n<div class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"functioncall\">xtabs<\/span>(~Sex, data = mm)\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## Sex\r\n##   0   1 \r\n## 273 327\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\">psych &lt;- mm[, 1:3]\r\nacad &lt;- mm[, 4:8]\r\n\r\n<span class=\"functioncall\">ggpairs<\/span>(psych)\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/cancor-unnamed-chunk-41.png\" alt=\"plot of chunk unnamed-chunk-4\" width=\"500px\" height=\"500px\" \/><\/div>\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"functioncall\">ggpairs<\/span>(acad)\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/cancor-unnamed-chunk-42.png\" alt=\"plot of chunk unnamed-chunk-4\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<p>For more information about GGally including packages such as ggduo() you can look <a href=\"http:\/\/ggobi.github.io\/ggally\/#canonical_correlation_analysis\">here<\/a>. Next, we&#8217;ll look at the correlations within and between the two sets of variables using the <code>matcor<\/code> function from the <code>CCA<\/code> package.<\/p>\n<div class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"comment\"># correlations<\/span>\r\n<span class=\"functioncall\">matcor<\/span>(psych, acad)\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## $Xcor\r\n##            Control Concept Motivation\r\n## Control     1.0000  0.1712     0.2451\r\n## Concept     0.1712  1.0000     0.2886\r\n## Motivation  0.2451  0.2886     1.0000\r\n## \r\n## $Ycor\r\n##             Read  Write     Math Science      Sex\r\n## Read     1.00000 0.6286  0.67928  0.6907 -0.04174\r\n## Write    0.62859 1.0000  0.63267  0.5691  0.24433\r\n## Math     0.67928 0.6327  1.00000  0.6495 -0.04822\r\n## Science  0.69069 0.5691  0.64953  1.0000 -0.13819\r\n## Sex     -0.04174 0.2443 -0.04822 -0.1382  1.00000\r\n## \r\n## $XYcor\r\n##            Control  Concept Motivation     Read   Write     Math  Science\r\n## Control     1.0000  0.17119     0.2451  0.37357 0.35888  0.33727  0.32463\r\n## Concept     0.1712  1.00000     0.2886  0.06066 0.01945  0.05360  0.06983\r\n## Motivation  0.2451  0.28857     1.0000  0.21061 0.25425  0.19501  0.11567\r\n## Read        0.3736  0.06066     0.2106  1.00000 0.62859  0.67928  0.69069\r\n## Write       0.3589  0.01945     0.2542  0.62859 1.00000  0.63267  0.56915\r\n## Math        0.3373  0.05360     0.1950  0.67928 0.63267  1.00000  0.64953\r\n## Science     0.3246  0.06983     0.1157  0.69069 0.56915  0.64953  1.00000\r\n## Sex         0.1134 -0.12595     0.0981 -0.04174 0.24433 -0.04822 -0.13819\r\n##                 Sex\r\n## Control     0.11341\r\n## Concept    -0.12595\r\n## Motivation  0.09810\r\n## Read       -0.04174\r\n## Write       0.24433\r\n## Math       -0.04822\r\n## Science    -0.13819\r\n## Sex         1.00000\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<h2>Some Strategies You Might Be Tempted To Try<\/h2>\n<p>Before we show how you can analyze this with a canonical correlation analysis, let&#8217;s\nconsider some other methods that you might use.<\/p>\n<ul>\n<li>Separate OLS Regressions &#8211; You could analyze these data using separate OLS regression\nanalyses for each variable in one set. The OLS regressions\nwill not produce multivariate results and does not report information\nconcerning dimensionality.<\/li>\n<li>Multivariate multiple regression is a reasonable option if you have\nno interest in dimensionality.<\/li>\n<\/ul>\n<h2>R Canonical Correlation Analysis<\/h2>\n<p>Due to the length of the output, we will be making comments in several places along\nthe way.<\/p>\n<div class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\">cc1 &lt;- <span class=\"functioncall\">cc<\/span>(psych, acad)\r\n\r\n<span class=\"comment\"># display the canonical correlations<\/span>\r\ncc1$cor\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## [1] 0.4641 0.1675 0.1040\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"comment\"># raw canonical coefficients<\/span>\r\ncc1[3:4]\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## $xcoef\r\n##               [,1]    [,2]    [,3]\r\n## Control    -1.2538 -0.6215 -0.6617\r\n## Concept     0.3513 -1.1877  0.8267\r\n## Motivation -1.2624  2.0273  2.0002\r\n## \r\n## $ycoef\r\n##              [,1]      [,2]      [,3]\r\n## Read    -0.044621 -0.004910  0.021381\r\n## Write   -0.035877  0.042071  0.091307\r\n## Math    -0.023417  0.004229  0.009398\r\n## Science -0.005025 -0.085162 -0.109835\r\n## Sex     -0.632119  1.084642 -1.794647\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>The raw canonical coefficients are interpreted in a manner analogous to interpreting\nregression coefficients i.e., for the variable <code>read<\/code>, a one unit increase in reading leads to a\n.0446 decrease in the first canonical variate of set 2 when all of\nthe other variables are held constant. Here is another example: being female leads to\na .6321 decrease in the dimension 1 for the academic set with the other predictors held constant.<\/p>\n<p>Next, we&#8217;ll use <code>comput<\/code> to compute the loadings of the\nvariables on the canonical dimensions (variates). These loadings are correlations between\nvariables and the canonical variates.<\/p>\n<div class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"comment\"># compute canonical loadings<\/span>\r\ncc2 &lt;- <span class=\"functioncall\">comput<\/span>(psych, acad, cc1)\r\n\r\n<span class=\"comment\"># display canonical loadings<\/span>\r\ncc2[3:6]\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## $corr.X.xscores\r\n##                [,1]    [,2]    [,3]\r\n## Control    -0.90405 -0.3897 -0.1756\r\n## Concept    -0.02084 -0.7087  0.7052\r\n## Motivation -0.56715  0.3509  0.7451\r\n## \r\n## $corr.Y.xscores\r\n##            [,1]     [,2]     [,3]\r\n## Read    -0.3900 -0.06011  0.01408\r\n## Write   -0.4068  0.01086  0.02647\r\n## Math    -0.3545 -0.04991  0.01537\r\n## Science -0.3056 -0.11337 -0.02395\r\n## Sex     -0.1690  0.12646 -0.05651\r\n## \r\n## $corr.X.yscores\r\n##                 [,1]     [,2]     [,3]\r\n## Control    -0.419555 -0.06528 -0.01826\r\n## Concept    -0.009673 -0.11872  0.07333\r\n## Motivation -0.263207  0.05878  0.07749\r\n## \r\n## $corr.Y.yscores\r\n##            [,1]     [,2]    [,3]\r\n## Read    -0.8404 -0.35883  0.1354\r\n## Write   -0.8765  0.06484  0.2546\r\n## Math    -0.7639 -0.29795  0.1478\r\n## Science -0.6584 -0.67680 -0.2304\r\n## Sex     -0.3641  0.75493 -0.5434\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>The above correlations are between observed variables and canonical variables\nwhich are known as the canonical loadings. These canonical variates are actually\na type of latent variable.<\/p>\n<p>In general, the number of canonical dimensions is\nequal to the number of variables in the smaller set; however, the number of significant\ndimensions may be even smaller. Canonical dimensions, also known as\ncanonical variates, are latent variables that are analogous to factors obtained in factor analysis.\nFor this particular model there are three canonical dimensions of which only the first\ntwo are statistically significant. For statistical test we use R package <code>\"CCP\"<\/code>.<\/p>\n<div id=\"unnamed-chunk-9\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"comment\"># tests of canonical dimensions<\/span>\r\n<span class=\"hl std\">rho<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl std\">cc1<\/span><span class=\"hl opt\">$<\/span><span class=\"hl std\">cor<\/span>\r\n<span class=\"comment\">## Define number of observations, number of variables in first set, and number of variables in the second set.<\/span>\r\n<span class=\"hl std\">n<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">dim<\/span><span class=\"hl std\">(psych)[<\/span><span class=\"hl num\">1<\/span><span class=\"hl std\">]<\/span>\r\n<span class=\"hl std\">p<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">length<\/span><span class=\"hl std\">(psych)<\/span>\r\n<span class=\"hl std\">q<\/span> <span class=\"hl kwb\">&lt;-<\/span> <span class=\"hl kwd\">length<\/span><span class=\"hl std\">(acad)<\/span>\r\n\r\n<span class=\"comment\">## Calculate p-values using the F-approximations of different test statistics:<\/span>\r\n<span class=\"hl kwd\">p.asym<\/span><span class=\"hl std\">(rho, n, p, q,<\/span> <span class=\"hl kwc\">tstat<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"Wilks\"<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## Wilks' Lambda, using F-approximation (Rao's F):\r\n##           stat approx df1  df2 p.value\r\n## 1 to 3:  0.754  11.72  15 1635 0.00000\r\n## 2 to 3:  0.961   2.94   8 1186 0.00291\r\n## 3 to 3:  0.989   2.16   3  594 0.09109\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">p.asym<\/span><span class=\"hl std\">(rho, n, p, q,<\/span> <span class=\"hl kwc\">tstat<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"Hotelling\"<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##  Hotelling-Lawley Trace, using F-approximation:\r\n##            stat approx df1  df2 p.value\r\n## 1 to 3:  0.3143  12.38  15 1772 0.00000\r\n## 2 to 3:  0.0398   2.95   8 1778 0.00281\r\n## 3 to 3:  0.0109   2.17   3 1784 0.09001\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">p.asym<\/span><span class=\"hl std\">(rho, n, p, q,<\/span> <span class=\"hl kwc\">tstat<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"Pillai\"<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##  Pillai-Bartlett Trace, using F-approximation:\r\n##            stat approx df1  df2 p.value\r\n## 1 to 3:  0.2542  11.00  15 1782 0.00000\r\n## 2 to 3:  0.0389   2.93   8 1788 0.00293\r\n## 3 to 3:  0.0108   2.16   3 1794 0.09044\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"hl kwd\">p.asym<\/span><span class=\"hl std\">(rho, n, p, q,<\/span> <span class=\"hl kwc\">tstat<\/span> <span class=\"hl std\">=<\/span> <span class=\"hl str\">\"Roy\"<\/span><span class=\"hl std\">)<\/span>\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##  Roy's Largest Root, using F-approximation:\r\n##           stat approx df1 df2 p.value\r\n## 1 to 1:  0.215   32.6   5 594       0\r\n## \r\n##  F statistic for Roy's Greatest Root is an upper bound.\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>As shown in the table above, the first test of the canonical dimensions tests whether\nall three dimensions are significant (they are, F = 11.72), the next test tests whether\ndimensions 2 and 3 combined are significant (they are, F = 2.94). Finally, the last test tests whether dimension\n3, by itself, is significant (it is not). Therefore dimensions 1 and 2 must each be\nsignificant while dimension three is not.<\/p>\n<p>When the variables in the model have very different standard deviations,\nthe standardized coefficients allow for easier comparisons among the variables. Next, we&#8217;ll\ncompute the standardized canonical coefficients.<\/p>\n<div class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"comment\"># standardized psych canonical coefficients diagonal matrix of psych sd's<\/span>\r\ns1 &lt;- <span class=\"functioncall\">diag<\/span>(<span class=\"functioncall\">sqrt<\/span>(<span class=\"functioncall\">diag<\/span>(<span class=\"functioncall\">cov<\/span>(psych))))\r\ns1 %*% cc1$xcoef\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##         [,1]    [,2]    [,3]\r\n## [1,] -0.8404 -0.4166 -0.4435\r\n## [2,]  0.2479 -0.8379  0.5833\r\n## [3,] -0.4327  0.6948  0.6855\r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"comment\"># standardized acad canonical coefficients diagonal matrix of acad sd's<\/span>\r\ns2 &lt;- <span class=\"functioncall\">diag<\/span>(<span class=\"functioncall\">sqrt<\/span>(<span class=\"functioncall\">diag<\/span>(<span class=\"functioncall\">cov<\/span>(acad))))\r\ns2 %*% cc1$ycoef\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##          [,1]     [,2]     [,3]\r\n## [1,] -0.45080 -0.04961  0.21601\r\n## [2,] -0.34896  0.40921  0.88810\r\n## [3,] -0.22047  0.03982  0.08848\r\n## [4,] -0.04878 -0.82660 -1.06608\r\n## [5,] -0.31504  0.54057 -0.89443\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>The standardized canonical coefficients are interpreted in a manner analogous to\ninterpreting standardized regression coefficients. For example, consider the\nvariable <code>read<\/code>, a one\nstandard deviation increase in reading leads to a 0.45 standard deviation\ndecrease in the\nscore on the first canonical variate for set 2 when the other variables in the model are\nheld constant.<\/p>\n<h2>Sample Write-Up of the Analysis<\/h2>\n<p>There is a lot of variation in the write-ups of canonical correlation analyses. The\nwrite-up below is fairly minimal, including only the tests of dimensionality and the\nstandardized coefficients.<\/p>\n<pre>Table 1: Tests of Canonical Dimensions\r\n            Canonical  Mult.\r\nDimension     Corr.      F    df1    df2      p\r\n    1         0.46     11.72   15   1634.7  0.0000\r\n    2         0.17      2.94    8   1186    0.0029\r\n    3         0.10      2.16    3    594    0.0911\r\n\r\nTable 2: Standardized Canonical Coefficients\r\n                            Dimension\r\n                           1         2\r\nPsychological Variables\r\n    locus of control    -0.84     -0.42\r\n    self-concept         0.25     -0.84\r\n    motivation          -0.43      0.69\r\nAcademic Variables plus Gender\r\n    reading             -0.45     -0.05\r\n    writing             -0.35      0.41\r\n    math                -0.22      0.04\r\n    science             -0.05     -0.83\r\n    gender (female=1)   -0.32      0.54\r\n<\/pre>\n<p>Tests of dimensionality for the canonical correlation analysis, as shown in Table 1, indicate\nthat two of the three canonical dimensions are statistically significant at the .05 level.\nDimension 1 had a canonical correlation of 0.46 between the sets of variables, while for\ndimension 2 the canonical correlation was much lower at 0.17.<\/p>\n<p>Table 2 presents\nthe standardized canonical coefficients for the first two dimensions across both sets of\nvariables. For the psychological variables, the first canonical dimension is most\nstrongly influenced by locus of control (-.84) and for the second dimension self-concept\n(-.84) and motivation (.69). For the academic variables plus gender, the first dimension\nwas comprised of reading (-.45), writing (-.35) and gender (-.32). For the second dimension\nwriting (.41), science (-.83) and gender (.54) were the dominating variables.<\/p>\n<h2>Cautions, Flies in the Ointment<\/h2>\n<ul>\n<li>Multivatiate normal distribution assumptions are required for both sets of variables.<\/li>\n<li>Canonical correlation analysis is not recommended for small samples.<\/li>\n<\/ul>\n<h2>See Also<\/h2>\n<h2>R Documentation<\/h2>\n<ul>\n<li><a href=\"https:\/\/cran.r-project.org\/web\/packages\/CCA\/CCA.pdf\">CCA Package<\/a><\/li>\n<\/ul>\n<ul>\n<li><a href=\"https:\/\/cran.r-project.org\/web\/packages\/CCP\/CCP.pdf\">CCP Package<\/a><\/li>\n<\/ul>\n<h2>References<\/h2>\n<ul>\n<li>Afifi, A, Clark, V and May, S. 2004. <i>Computer-Aided Multivariate Analysis.<\/i> 4th ed.\nBoca Raton, Fl: Chapman &amp; Hall\/CRC.<\/li>\n<\/ul>\n<p><!--?php include \"stat\/footer.htm\"; ?--><\/p>\n","protected":false},"excerpt":{"rendered":"<p>Canonical correlation analysis is used to identify and measure the associations among two sets of variables. Canonical correlation is appropriate in the same situations where multiple regression would be, but&#8230;<br><a class=\"moretag\" href=\"https:\/\/stats.oarc.ucla.edu\/r\/dae\/canonical-correlation-analysis\/\"> Read More<\/a><\/p>\n","protected":false},"author":1,"featured_media":0,"parent":916,"menu_order":0,"comment_status":"closed","ping_status":"closed","template":"","meta":{"_genesis_hide_title":false,"_genesis_hide_breadcrumbs":false,"_genesis_hide_singular_image":false,"_genesis_hide_footer_widgets":false,"_genesis_custom_body_class":"","_genesis_custom_post_class":"","_genesis_layout":"","footnotes":""},"class_list":["post-917","page","type-page","status-publish","entry"],"_links":{"self":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/917","targetHints":{"allow":["GET"]}}],"collection":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/comments?post=917"}],"version-history":[{"count":9,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/917\/revisions"}],"predecessor-version":[{"id":36794,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/917\/revisions\/36794"}],"up":[{"embeddable":true,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/916"}],"wp:attachment":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/media?parent=917"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}