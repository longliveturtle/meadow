{"id":926,"date":"2016-02-11T18:29:03","date_gmt":"2016-02-11T18:29:03","guid":{"rendered":"http:\/\/dev2.hpc.ucla.edu\/r\/dae-3\/r-data-analysis-examples-negative-binomial-regression\/"},"modified":"2021-05-18T15:54:55","modified_gmt":"2021-05-18T22:54:55","slug":"negative-binomial-regression","status":"publish","type":"page","link":"https:\/\/stats.oarc.ucla.edu\/r\/dae\/negative-binomial-regression\/","title":{"rendered":"Negative Binomial Regression |  R Data Analysis Examples"},"content":{"rendered":"<p>Negative binomial regression is for modeling count variables, usually for\nover-dispersed count outcome variables.<\/p>\n<p>This page uses the following packages. Make sure that you can load\nthem before trying to run the examples on this page. If you do not have\na package installed, run: <code>install.packages(\"packagename\")<\/code>, or\nif you see the version is out of date, run: <code>update.packages()<\/code>.<\/p>\n<div id=\"unnamed-chunk-2\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"functioncall\">require<\/span>(foreign)\r\n<span class=\"functioncall\">require<\/span>(ggplot2)\r\n<span class=\"functioncall\">require<\/span>(MASS)\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p><code class=\"knitr inline\"><strong>Version info: <\/strong>Code for this page was tested in R Under development (unstable) (2013-01-06 r61571)\nOn: 2013-01-22\nWith: MASS 7.3-22; ggplot2 0.9.3; foreign 0.8-52; knitr 1.0.5\n<\/code><\/p>\n<p><strong>Please note:<\/strong> The purpose of this\npage is to show how to use various data analysis commands. It does not cover\nall aspects of the research process which researchers are expected to do. In\nparticular, it does not cover data cleaning and checking, verification of\nassumptions, model diagnostics or potential follow-up analyses.<\/p>\n<h2>Examples of negative binomial regression<\/h2>\n<p>Example 1. School administrators study the attendance behavior of high\nschool juniors at two schools. Predictors of the number of days of absence\ninclude the type of program in which the student is enrolled and a standardized\ntest in math.<\/p>\n<p>Example 2. A health-related researcher is studying the number of hospital\nvisits in past 12 months by senior citizens in a community based on the\ncharacteristics of the individuals and the types of health plans under which\neach one is covered.<\/p>\n<h2>Description of the data<\/h2>\n<p>Let&#8217;s pursue Example 1 from above.<\/p>\n<p>We have attendance data on 314 high school juniors from two urban high schools in\nthe file <code>nb_data<\/code>. The response variable of interest is days absent, <code>daysabs<\/code>.\nThe variable <code>math<\/code> gives the standardized math score for\neach student. The variable <code>prog<\/code> is a three-level nominal variable indicating the\ntype of instructional program in which the student is enrolled.<\/p>\n<p>Let&#8217;s look at the data. It is always a good idea to start with descriptive statistics and plots.<\/p>\n<div id=\"unnamed-chunk-3\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\">dat &lt;- <span class=\"functioncall\">read.dta<\/span>(<span class=\"string\">\"https:\/\/stats.idre.ucla.edu\/stat\/stata\/dae\/nb_data.dta\"<\/span>)\r\ndat &lt;- <span class=\"functioncall\">within<\/span>(dat, {\r\n    prog &lt;- <span class=\"functioncall\">factor<\/span>(prog, levels = 1:3, labels = <span class=\"functioncall\">c<\/span>(<span class=\"string\">\"General\"<\/span>, <span class=\"string\">\"Academic\"<\/span>, <span class=\"string\">\"Vocational\"<\/span>))\r\n    id &lt;- <span class=\"functioncall\">factor<\/span>(id)\r\n})\r\n\r\n<span class=\"functioncall\">summary<\/span>(dat)\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##        id         gender         math         daysabs     \r\n##  1001   :  1   female:160   Min.   : 1.0   Min.   : 0.00  \r\n##  1002   :  1   male  :154   1st Qu.:28.0   1st Qu.: 1.00  \r\n##  1003   :  1                Median :48.0   Median : 4.00  \r\n##  1004   :  1                Mean   :48.3   Mean   : 5.96  \r\n##  1005   :  1                3rd Qu.:70.0   3rd Qu.: 8.00  \r\n##  1006   :  1                Max.   :99.0   Max.   :35.00  \r\n##  (Other):308                                              \r\n##          prog    \r\n##  General   : 40  \r\n##  Academic  :167  \r\n##  Vocational:107  \r\n##                  \r\n##                  \r\n##                  \r\n## \r\n<\/pre>\n<\/div>\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"functioncall\">ggplot<\/span>(dat, <span class=\"functioncall\">aes<\/span>(daysabs, fill = prog)) + <span class=\"functioncall\">geom_histogram<\/span>(binwidth = 1) + <span class=\"functioncall\">facet_grid<\/span>(prog ~ \r\n    ., margins = <span class=\"keyword\">TRUE<\/span>, scales = <span class=\"string\">\"free\"<\/span>)\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/nbreg-unnamed-chunk-3.png\" alt=\"Histogram plots showing distribution of the data\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<p>Each variable has 314 valid observations and their distributions seem quite reasonable.\nThe unconditional mean of our outcome variable is much lower than its variance.<\/p>\n<p>Let&#8217;s continue with our description of the variables in this dataset.\nThe table below shows the average numbers of days absent by program type\nand seems to suggest that program type is a good candidate for predicting the number of\ndays absent, our outcome variable, because the mean value of the outcome appears to vary by\n<code>prog<\/code>. The variances within each level of <code>prog<\/code> are\nhigher than the means within each level. These are the conditional means and\nvariances. These differences suggest that over-dispersion is present and that a\nNegative Binomial model would be appropriate.<\/p>\n<div id=\"unnamed-chunk-4\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"functioncall\">with<\/span>(dat, <span class=\"functioncall\">tapply<\/span>(daysabs, prog, <span class=\"functioncall\"><span class=\"keyword\">function<\/span><\/span>(x) {\r\n    <span class=\"functioncall\">sprintf<\/span>(<span class=\"string\">\"<span class=\"functioncall\">M<\/span> (SD) = %<span class=\"functioncall\">1.2f<\/span> (%1.2f)\"<\/span>, <span class=\"functioncall\">mean<\/span>(x), <span class=\"functioncall\">sd<\/span>(x))\r\n}))\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##                 General                Academic              Vocational \r\n## \"M (SD) = 10.65 (8.20)\"  \"M (SD) = 6.93 (7.45)\"  \"M (SD) = 2.67 (3.73)\"\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<h2>Analysis methods you might consider<\/h2>\n<p>Below is a list of some analysis methods you may have\nencountered. Some of the methods listed are quite reasonable, while others have\neither fallen out of favor or have limitations.<\/p>\n<ul>\n<li>Negative binomial regression -Negative binomial regression can be used\nfor over-dispersed count data, that is when the conditional variance exceeds\nthe conditional mean. It can be considered as a generalization of Poisson\nregression since it has the same mean structure as Poisson regression and it\nhas an extra parameter to model the over-dispersion.\u00a0If the conditional\ndistribution of the outcome variable is over-dispersed, the confidence\nintervals for the Negative binomial regression are likely to be wider as\ncompared to those from a Poisson regression model.<\/li>\n<li>Poisson regression &#8211; Poisson regression is often used for modeling count\ndata. Poisson regression has a number of extensions useful for count models.<\/li>\n<li>Zero-inflated regression model &#8211; Zero-inflated models attempt to account\nfor excess zeros. In other words, two kinds of zeros are thought to exist\nin the data, &#8220;true zeros&#8221; and &#8220;excess zeros&#8221;. Zero-inflated models estimate\ntwo equations simultaneously, one for the count model and one for the excess\nzeros.<\/li>\n<li>OLS regression &#8211; Count outcome variables are sometimes log-transformed\nand analyzed using OLS regression. Many issues arise with this approach,\nincluding loss of data due to undefined values generated by taking the log\nof zero (which is undefined), as well as the lack of capacity to model the\ndispersion.<\/li>\n<\/ul>\n<h2>Negative binomial regression analysis<\/h2>\n<p>Below we use the <code>glm.nb<\/code> function from the <code>MASS<\/code> package to\nestimate a negative binomial regression.<\/p>\n<div id=\"unnamed-chunk-5\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"functioncall\">summary<\/span>(m1 &lt;- <span class=\"functioncall\">glm.nb<\/span>(daysabs ~ math + prog, data = dat))\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## \r\n## Call:\r\n## glm.nb(formula = daysabs ~ math + prog, data = dat, init.theta = 1.032713156, \r\n##     link = log)\r\n## \r\n## Deviance Residuals: \r\n##    Min      1Q  Median      3Q     Max  \r\n## -2.155  -1.019  -0.369   0.229   2.527  \r\n## \r\n## Coefficients:\r\n##                Estimate Std. Error z value Pr(&gt;|z|)    \r\n## (Intercept)     2.61527    0.19746   13.24  &lt; 2e-16 ***\r\n## math           -0.00599    0.00251   -2.39    0.017 *  \r\n## progAcademic   -0.44076    0.18261   -2.41    0.016 *  \r\n## progVocational -1.27865    0.20072   -6.37  1.9e-10 ***\r\n## ---\r\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n## \r\n## (Dispersion parameter for Negative Binomial(1.033) family taken to be 1)\r\n## \r\n##     Null deviance: 427.54  on 313  degrees of freedom\r\n## Residual deviance: 358.52  on 310  degrees of freedom\r\n## AIC: 1741\r\n## \r\n## Number of Fisher Scoring iterations: 1\r\n## \r\n## \r\n##               Theta:  1.033 \r\n##           Std. Err.:  0.106 \r\n## \r\n##  2 x log-likelihood:  -1731.258\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<ul>\n<li style=\"list-style-type: none;\">\n<ul>\n<li>R first displays the call and the deviance residuals. Next, we see the\nregression coefficients for each of the variables, along with standard\nerrors, z-scores, and p-values. The variable <code>math<\/code> has a coefficient\nof -0.006, which is statistically significant. This means that for each\none-unit increase in <code>math<\/code>, the expected log count of the number of\ndays absent decreases by 0.006. The indicator variable shown as <code>progAcademic<\/code>\nis the expected difference in log count between group 2 and the reference\ngroup (<code>prog<\/code>=1). The expected log count for level 2 of <code>prog<\/code> is\n0.44 lower than the expected log count for level 1. The indicator variable\nfor <code>progVocational<\/code> is the expected difference in log count between\ngroup 3 and the reference group.The expected log count for level 3 of <code>\nprog<\/code> is 1.28 lower than the expected log count for level 1. To\ndetermine if <code>prog<\/code> itself, overall, is statistically significant, we\ncan compare a model with and without <code>prog<\/code>. The reason it is important\nto fit separate models, is that unless we do, the overdispersion parameter is\nheld constant.<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<div id=\"unnamed-chunk-6\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\">m2 &lt;- <span class=\"functioncall\">update<\/span>(m1, . ~ . - prog)\r\n<span class=\"functioncall\">anova<\/span>(m1, m2)\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## Likelihood ratio tests of Negative Binomial Models\r\n## \r\n## Response: daysabs\r\n##         Model  theta Resid. df    2 x log-lik.   Test    df LR stat.\r\n## 1        math 0.8559       312           -1776                      \r\n## 2 math + prog 1.0327       310           -1731 1 vs 2     2    45.05\r\n##     Pr(Chi)\r\n## 1          \r\n## 2 1.652e-10\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<ul>\n<li>The two degree-of-freedom chi-square test indicates that <code>prog<\/code> is\na statistically significant predictor of <code>daysabs<\/code>.<\/li>\n<li>The null deviance is calculated from an intercept-only model with 313\ndegrees of freedom. Then we see the residual deviance, the deviance from the\nfull model. We are also shown the AIC and 2*log likelihood.<\/li>\n<li>The theta parameter shown is the dispersion parameter. Note that R\nparameterizes this differently from SAS, Stata, and SPSS. The R parameter\n(theta) is equal to the inverse of the dispersion parameter (alpha)\nestimated in these other software packages. Thus, the theta value of 1.033\nseen here is equivalent to the 0.968 value seen in the\n<a href=\"\/stata\/dae\/negative-binomial-regression\/\">Stata Negative Binomial\nData Analysis Example<\/a> because 1\/0.968 = 1.033.<\/li>\n<\/ul>\n<h2>Checking model assumption<\/h2>\n<p>As we mentioned earlier, negative binomial models assume the conditional means\nare not equal to the conditional variances. This inequality is captured by\nestimating a dispersion parameter (not shown in the output) that is held\nconstant in a Poisson model. Thus, the Poisson\nmodel is actually nested in the negative binomial model. We can then use a\nlikelihood ratio test to compare these two and test this model assumption. To do this, we will run our model as\na Poisson.<\/p>\n<div id=\"unnamed-chunk-7\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\">m3 &lt;- <span class=\"functioncall\">glm<\/span>(daysabs ~ math + prog, family = <span class=\"string\">\"poisson\"<\/span>, data = dat)\r\n<span class=\"functioncall\">pchisq<\/span>(2 * (<span class=\"functioncall\">logLik<\/span>(m1) - <span class=\"functioncall\">logLik<\/span>(m3)), df = 1, lower.tail = <span class=\"keyword\">FALSE<\/span>)\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">## 'log Lik.' 2.157e-203 (df=5)\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>In this example the associated chi-squared value estimated from 2*(logLik(m1) &#8211; logLik(m3)) is 926.03 with one degree\nof freedom. This strongly suggests the negative binomial model,\nestimating the dispersion parameter, is more\nappropriate than the Poisson model.<\/p>\n<p>We can get the confidence intervals for the coefficients by\nprofiling the likelihood function.<\/p>\n<div id=\"unnamed-chunk-8\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\">(est &lt;- <span class=\"functioncall\">cbind<\/span>(Estimate = <span class=\"functioncall\">coef<\/span>(m1), <span class=\"functioncall\">confint<\/span>(m1)))\r\n<\/pre>\n<\/div>\n<div class=\"message\">\n<pre class=\"knitr r\">## Waiting for profiling to be done...\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##                 Estimate   2.5 %    97.5 %\r\n## (Intercept)     2.615265  2.2421  3.012936\r\n## math           -0.005993 -0.0109 -0.001067\r\n## progAcademic   -0.440760 -0.8101 -0.092643\r\n## progVocational -1.278651 -1.6835 -0.890078\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>We might be interested in looking at incident rate ratios rather than\ncoefficients. To do this, we can exponentiate our model coefficients. The same\napplies to the confidence intervals.<\/p>\n<div id=\"unnamed-chunk-9\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\"><span class=\"functioncall\">exp<\/span>(est)\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##                Estimate  2.5 %  97.5 %\r\n## (Intercept)     13.6708 9.4127 20.3470\r\n## math             0.9940 0.9892  0.9989\r\n## progAcademic     0.6435 0.4448  0.9115\r\n## progVocational   0.2784 0.1857  0.4106\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>The output above indicates that the incident rate for <code>prog<\/code> = 2\nis 0.64 times the incident rate for the reference group (<code>prog<\/code> = 1).\nLikewise, the incident rate for <code>prog<\/code> = 3 is 0.28 times the incident\nrate for the reference group holding the other variables constant. The\npercent change in the incident rate of <code>daysabs<\/code> is a 1% decrease\nfor every unit increase in <code>math<\/code>.<\/p>\n<p>The form of the model equation for negative binomial regression is\nthe same as that for Poisson regression. The log of the expected outcome is\npredicted with a linear combination of the predictors:<\/p>\n<p>\\[\nln(\\widehat{daysabs_i}) = Intercept + b_1I(prog_i = 2) + b_2I(prog_i = 3) + b_3math_i\n\\]<\/p>\n<p>where $I(prog_i = j)$ is an indicator function such that if\u00a0 $prog_i = j$ is equal to 1 and otherwise is equal to 0, for $j \\in \\{2, 3\\}$. Therefore,<\/p>\n<p>\\[\n\\widehat{daysabs_i} = e^{Intercept + b_1 I(prog_i = 2) + b_2I(prog_i = 3) + b_3 math_i} =\ne^{Intercept}e^{b_1 I(prog_i = 2)}e^{b_2 I(prog_i = 3)}e^{b_3\u00a0 math_i}\n\\]<\/p>\n<p>The coefficients have an <em>additive<\/em> effect in the $ln(y)$ scale\nand the IRR have a <em>multiplicative<\/em> effect in the $y$ scale. The\ndispersion parameter in negative binomial regression\ndoes not affect the expected counts, but it does affect the estimated variance of\nthe expected counts. More details can be found in the <i>Modern Applied\nStatistics with S<\/i> by W.N. Venables and B.D. Ripley (the book\ncompanion of the <code>MASS<\/code> package).<\/p>\n<p>For additional information on the various metrics in which the\nresults can be presented, and the interpretation of such, please see <i>\nRegression Models for Categorical Dependent Variables Using Stata,\nSecond Edition<\/i> by J. Scott Long and Jeremy Freese (2006).<\/p>\n<h2>Predicted values<\/h2>\n<p>For assistance in further understanding the model, we can look at predicted\ncounts for various levels of our predictors. Below we create new datasets with\nvalues of <code>math<\/code> and <code>prog<\/code> and then use the <code>predict<\/code> command to\ncalculate the predicted number of events.<\/p>\n<p>First, we can look at predicted counts for each value of <code>prog<\/code> while\nholding <code>math<\/code> at its mean.\nTo do this, we create a new dataset with the combinations of <code>prog<\/code> and\n<code>math<\/code> for which we would like to find predicted values, then use the <code>predict<\/code>\ncommand.<\/p>\n<div id=\"unnamed-chunk-10\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\">newdata1 &lt;- <span class=\"functioncall\">data.frame<\/span>(math = <span class=\"functioncall\">mean<\/span>(dat$math), prog = <span class=\"functioncall\">factor<\/span>(1:3, levels = 1:3, \r\n    labels = <span class=\"functioncall\">levels<\/span>(dat$prog)))\r\nnewdata1$phat &lt;- <span class=\"functioncall\">predict<\/span>(m1, newdata1, type = <span class=\"string\">\"response\"<\/span>)\r\nnewdata1\r\n<\/pre>\n<\/div>\n<div class=\"output\">\n<pre class=\"knitr r\">##    math       prog   phat\r\n## 1 48.27    General 10.237\r\n## 2 48.27   Academic  6.588\r\n## 3 48.27 Vocational  2.850\r\n<\/pre>\n<\/div>\n<\/div>\n<\/div>\n<p>In the output above, we see that the predicted number of events (e.g., days\nabsent) for a general program is about 10.24, holding <code>math<\/code> at its mean. The predicted\nnumber of events for an academic program is lower at 6.59, and the\npredicted number of events for a vocational program is about 2.85.<\/p>\n<p>Below we will obtain the mean predicted number of events for values of <code>math<\/code>\nacross its entire range for each level of <code>prog<\/code> and graph these.<\/p>\n<div id=\"unnamed-chunk-11\" class=\"chunk\">\n<div class=\"rcode\">\n<div class=\"source\">\n<pre class=\"knitr r\">newdata2 &lt;- <span class=\"functioncall\">data.frame<\/span>(\r\n  math = <span class=\"functioncall\">rep<\/span>(<span class=\"functioncall\">seq<\/span>(from = <span class=\"functioncall\">min<\/span>(dat$math), to = <span class=\"functioncall\">max<\/span>(dat$math), length.out = 100), 3),\r\n  prog = <span class=\"functioncall\">factor<\/span>(<span class=\"functioncall\">rep<\/span>(1:3, each = 100), levels = 1:3, labels =\r\n  <span class=\"functioncall\">levels<\/span>(dat$prog)))\r\n\r\nnewdata2 &lt;- <span class=\"functioncall\">cbind<\/span>(newdata2, <span class=\"functioncall\">predict<\/span>(m1, newdata2, type = <span class=\"string\">\"link\"<\/span>, se.fit=<span class=\"keyword\">TRUE<\/span>))\r\nnewdata2 &lt;- <span class=\"functioncall\">within<\/span>(newdata2, {\r\n  DaysAbsent &lt;- <span class=\"functioncall\">exp<\/span>(fit)\r\n  LL &lt;- <span class=\"functioncall\">exp<\/span>(fit - 1.96 * se.fit)\r\n  UL &lt;- <span class=\"functioncall\">exp<\/span>(fit + 1.96 * se.fit)\r\n})\r\n\r\n<span class=\"functioncall\">ggplot<\/span>(newdata2, <span class=\"functioncall\">aes<\/span>(math, DaysAbsent)) +\r\n  <span class=\"functioncall\">geom_ribbon<\/span>(<span class=\"functioncall\">aes<\/span>(ymin = LL, ymax = UL, fill = prog), alpha = .25) +\r\n  <span class=\"functioncall\">geom_line<\/span>(<span class=\"functioncall\">aes<\/span>(colour = prog), size = 2) +\r\n  <span class=\"functioncall\">labs<\/span>(x = <span class=\"string\">\"Math Score\"<\/span>, y = <span class=\"string\">\"Predicted Days Absent\"<\/span>)\r\n<\/pre>\n<\/div>\n<\/div>\n<div class=\"rimage default\"><img decoding=\"async\" class=\"plot\" src=\"https:\/\/stats.idre.ucla.edu\/wp-content\/uploads\/2016\/02\/nbreg-unnamed-chunk-11.png\" alt=\"Plot of the model predicted days absent with confidence intervals\" width=\"500px\" height=\"500px\" \/><\/div>\n<\/div>\n<p>The graph shows the expected count across the range of math scores,\nfor each type of program along with 95 percent confidence intervals.\nNote that the lines are not straight because this is a log linear model, and\nwhat is plotted are the expected values, not the log of the expected values.<\/p>\n<h2>Things to consider<\/h2>\n<ul>\n<li>It is not recommended that negative binomial models be applied to small\nsamples.<\/li>\n<li>One common cause of over-dispersion is excess zeros by an additional\ndata generating process. In this situation, zero-inflated model should be\nconsidered.<\/li>\n<li>If the data generating process does not allow for any 0s (such as the\nnumber of days spent in the hospital), then a zero-truncated model may be\nmore appropriate.<\/li>\n<li>Count data often have an exposure variable, which indicates the number\nof times the event could have happened. This variable should be\nincorporated into your negative binomial regression model with the use of\nthe <code>offset<\/code> option. See the <code>glm<\/code> documentation for details.<\/li>\n<li>The outcome variable in a negative binomial regression cannot have negative numbers.<\/li>\n<li>You will need to use the <code>m1$resid<\/code> command to obtain the residuals\nfrom our model to check other assumptions\nof the negative binomial model (see Cameron and Trivedi (1998) and Dupont (2002) for\nmore information).<\/li>\n<\/ul>\n<h2>References<\/h2>\n<ul>\n<li>Long, J. S. 1997. <i>Regression Models for Categorical and Limited Dependent Variables.<\/i>\nThousand Oaks, CA: Sage Publications.<\/li>\n<li>Long, J. S. and Freese, J. 2006. <i>Regression Models for\nCategorical Dependent Variables Using Stata, Second Edition<\/i>.\nCollege Station, TX: Stata Press.<\/li>\n<li>Cameron, A. C. and Trivedi, P. K. 2009. <i>Microeconometrics Using\nStata<\/i>. College Station, TX: Stata Press.<\/li>\n<li>Cameron, A. C. and Trivedi, P. K. 1998. <i>Regression\nAnalysis of Count Data<\/i>. New York: Cambridge Press.<\/li>\n<li>Cameron, A. C. Advances in Count Data Regression Talk for the\nApplied Statistics Workshop, March 28, 2009.\n<a href=\"http:\/\/cameron.econ.ucdavis.edu\/racd\/count.html\">\nhttp:\/\/cameron.econ.ucdavis.edu\/racd\/count.html<\/a> .<\/li>\n<li>Dupont, W. D. 2002. <i>Statistical Modeling for Biomedical\nResearchers: A Simple Introduction to the Analysis of Complex Data.<\/i>\nNew York: Cambridge Press.<\/li>\n<li>Venables, W.N. and Ripley, B.D. 2002. <i>Modern Applied Statistics with\nS, Fourth Edition<\/i>. New York: Springer.<\/li>\n<\/ul>\n<h2>See also<\/h2>\n<ul>\n<li>R online documentation:\n<a href=\"http:\/\/stat.ethz.ch\/R-manual\/R-patched\/library\/stats\/html\/glm.html\">glm<\/a><\/li>\n<\/ul>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n","protected":false},"excerpt":{"rendered":"<p>Negative binomial regression is for modeling count variables, usually for over-dispersed count outcome variables. This page uses the following packages. Make sure that you can load them before trying to&#8230;<br><a class=\"moretag\" href=\"https:\/\/stats.oarc.ucla.edu\/r\/dae\/negative-binomial-regression\/\"> Read More<\/a><\/p>\n","protected":false},"author":1,"featured_media":0,"parent":916,"menu_order":8,"comment_status":"closed","ping_status":"closed","template":"","meta":{"_genesis_hide_title":false,"_genesis_hide_breadcrumbs":false,"_genesis_hide_singular_image":false,"_genesis_hide_footer_widgets":false,"_genesis_custom_body_class":"","_genesis_custom_post_class":"","_genesis_layout":"","footnotes":""},"class_list":["post-926","page","type-page","status-publish","entry"],"_links":{"self":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/926","targetHints":{"allow":["GET"]}}],"collection":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/comments?post=926"}],"version-history":[{"count":6,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/926\/revisions"}],"predecessor-version":[{"id":35281,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/926\/revisions\/35281"}],"up":[{"embeddable":true,"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/pages\/916"}],"wp:attachment":[{"href":"https:\/\/stats.oarc.ucla.edu\/wp-json\/wp\/v2\/media?parent=926"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}